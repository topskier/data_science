{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c032d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd7e0b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Байесовский линейный слой\n",
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, prior_sigma=1.0):\n",
    "        super(BayesianLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # Параметры апостериорного распределения весов\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).normal_(0, 0.1))\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).normal_(-3, 0.1))\n",
    "        \n",
    "        # Параметры апостериорного распределения смещений\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).normal_(0, 0.1))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).normal_(-3, 0.1))\n",
    "        \n",
    "        # Априорное распределение\n",
    "        self.prior_sigma = prior_sigma\n",
    "        # self.register_buffer('weight_prior', Normal(0, prior_sigma))\n",
    "        # self.register_buffer('bias_prior', Normal(0, prior_sigma))\n",
    "        \n",
    "    @property\n",
    "    def weight_sigma(self):\n",
    "        return torch.log1p(torch.exp(self.weight_rho))\n",
    "    \n",
    "    @property\n",
    "    def bias_sigma(self):\n",
    "        return torch.log1p(torch.exp(self.bias_rho))\n",
    "    \n",
    "    def forward(self, x, sample=True):\n",
    "        if self.training or sample:\n",
    "            # Сэмплирование весов во время обучения\n",
    "            weight_epsilon = torch.randn_like(self.weight_mu)\n",
    "            bias_epsilon = torch.randn_like(self.bias_mu)\n",
    "            \n",
    "            weight = self.weight_mu + self.weight_sigma * weight_epsilon\n",
    "            bias = self.bias_mu + self.bias_sigma * bias_epsilon\n",
    "        else:\n",
    "            # Использование средних значений во время инференса\n",
    "            weight = self.weight_mu\n",
    "            bias = self.bias_mu\n",
    "            \n",
    "        return F.linear(x, weight, bias)\n",
    "    \n",
    "    def kl_loss(self):\n",
    "        # Создаем априорные распределения на лету\n",
    "        weight_prior = Normal(0, self.prior_sigma)\n",
    "        bias_prior = Normal(0, self.prior_sigma)\n",
    "        \n",
    "        # Апостериорные распределения\n",
    "        weight_dist = Normal(self.weight_mu, self.weight_sigma)\n",
    "        bias_dist = Normal(self.bias_mu, self.bias_sigma)\n",
    "        \n",
    "        kl = kl_divergence(weight_dist, weight_prior).sum()\n",
    "        kl += kl_divergence(bias_dist, bias_prior).sum()\n",
    "        \n",
    "        return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e832f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Байесовская нейронная сеть\n",
    "class BayesianInsuranceNet(nn.Module):\n",
    "    def __init__(self, input_size, prior_sigma=1.0):\n",
    "        super(BayesianInsuranceNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = BayesianLinear(input_size, 72, prior_sigma)\n",
    "        self.layer2 = BayesianLinear(72, 64, prior_sigma)\n",
    "        self.layer3 = BayesianLinear(64, 54, prior_sigma)\n",
    "        self.layer4 = BayesianLinear(54, 36, prior_sigma)\n",
    "        self.layer5 = BayesianLinear(36, 24, prior_sigma)\n",
    "        self.layer6 = BayesianLinear(24, 1, prior_sigma)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, sample=True):\n",
    "        x = self.relu(self.layer1(x, sample))\n",
    "        x = self.relu(self.layer2(x, sample))\n",
    "        x = self.relu(self.layer3(x, sample))\n",
    "        x = self.relu(self.layer4(x, sample))\n",
    "        x = self.relu(self.layer5(x, sample))\n",
    "        x = self.sigmoid(self.layer6(x, sample))\n",
    "        return x\n",
    "    \n",
    "    def kl_loss(self):\n",
    "        kl = 0\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, BayesianLinear):\n",
    "                kl += module.kl_loss()\n",
    "        return kl\n",
    "# Функция потерь для байесовской сети\n",
    "def bayesian_loss(prediction, target, model, kl_weight=0.1):\n",
    "    likelihood_loss = F.binary_cross_entropy(prediction, target)\n",
    "    kl_loss = model.kl_loss()\n",
    "    total_loss = likelihood_loss + kl_weight * kl_loss\n",
    "    return total_loss, likelihood_loss, kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91551dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение байесовской модели\n",
    "def train_bayesian_model(model, X_train, y_train, epochs=350, kl_weight=0.1):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход с сэмплированием весов\n",
    "        outputs = model(X_train, sample=True)\n",
    "        total_loss, likelihood_loss, kl_loss = bayesian_loss(outputs, y_train, model, kl_weight)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Total Loss: {total_loss.item():.4f}, '\n",
    "                  f'Likelihood: {likelihood_loss.item():.4f}, KL: {kl_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb47b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание с учетом uncertainty\n",
    "def predict_with_uncertainty(model, X, num_samples=50):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            pred = model(X, sample=True)\n",
    "            predictions.append(pred.numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    mean_prediction = predictions.mean(axis=0)\n",
    "    std_prediction = predictions.std(axis=0)\n",
    "    \n",
    "    return mean_prediction, std_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f92661b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Существующие датовые колонки для обработки: ['Date_birth', 'Date_driving_licence']\n"
     ]
    }
   ],
   "source": [
    "print(\"Загрузка данных...\")\n",
    "data = pd.read_csv('D:/my_ML/diploma_polytech/data/raw/vehicle_ins_data_1.csv', sep=\";\", index_col=False, low_memory=False)\n",
    "\n",
    "# Создание целевой переменной: 1 если N_claims_year > 1, иначе 0\n",
    "data['claim_prob'] = (data['N_claims_year'] > 1).astype(int)\n",
    "\n",
    "# Предобработка данных\n",
    "# Удаление ненужных столбцов, но НЕ УДАЛЯЕМ Date_start_contract\n",
    "cols_to_drop = ['ID', 'Date_last_renewal', 'Date_next_renewal', \n",
    "                'Date_lapse', 'N_claims_year', 'Cost_claims_year', 'N_claims_history', \n",
    "                'R_Claims_history']\n",
    "data = data.drop(columns=cols_to_drop)\n",
    "\n",
    "# Преобразуем Date_start_contract в datetime ДО любой обработки\n",
    "data['Date_start_contract'] = pd.to_datetime(data['Date_start_contract'], errors='coerce')\n",
    "\n",
    "# Обработка датовых колонок\n",
    "date_columns = ['Date_birth', 'Date_driving_licence']\n",
    "existing_date_columns = [col for col in date_columns if col in data.columns]\n",
    "\n",
    "print(\"Существующие датовые колонки для обработки:\", existing_date_columns)\n",
    "\n",
    "if not existing_date_columns:\n",
    "    print(\"Предупреждение: Датовые колонки не найдены в DataFrame.\")\n",
    "else:\n",
    "    for col in existing_date_columns:\n",
    "        data[col] = pd.to_datetime(data[col], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Извлечение числовых признаков из дат\n",
    "reference_date = pd.to_datetime('2019-12-31')\n",
    "\n",
    "if 'Date_birth' in data.columns:\n",
    "    data['Age'] = (reference_date - data['Date_birth']).dt.days // 365\n",
    "\n",
    "if 'Date_driving_licence' in data.columns:\n",
    "    data['Driving_experience'] = (reference_date - data['Date_driving_licence']).dt.days // 365\n",
    "\n",
    "# Удаление исходных датовых колонок\n",
    "data = data.drop(columns=date_columns, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13f3b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер данных после предобработки: (105555, 23)\n",
      "Баланс классов: claim_prob\n",
      "0.0    95448\n",
      "1.0    10107\n",
      "Name: count, dtype: int64\n",
      "Размер тренировочной выборки: torch.Size([84444, 22])\n",
      "Размер тестовой выборки: torch.Size([21111, 22])\n",
      "\n",
      "Инициализирована байесовская нейронная сеть с 22 входными признаками\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Обработка категориальных переменных\n",
    "categorical_cols = ['Type_fuel']\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in data.columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Убедиться, что все данные числовые\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "data = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "\n",
    "print(f\"Размер данных после предобработки: {data.shape}\")\n",
    "print(f\"Баланс классов: {data['claim_prob'].value_counts()}\")\n",
    "\n",
    "# Разделение на признаки и целевую переменную\n",
    "X = data.drop(columns=['claim_prob'])\n",
    "y = data['claim_prob']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Масштабирование признаков\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Преобразование в тензоры PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "print(f\"Размер тренировочной выборки: {X_train_tensor.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test_tensor.shape}\")\n",
    "\n",
    "# Инициализация байесовской модели\n",
    "input_size = X_train_tensor.shape[1]\n",
    "bayesian_model = BayesianInsuranceNet(input_size, prior_sigma=1.0)\n",
    "\n",
    "print(f\"\\nИнициализирована байесовская нейронная сеть с {input_size} входными признаками\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1611ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Начало обучения байесовской нейронной сети...\n",
      "Epoch [10/500], Total Loss: 3209.6406, Likelihood: 0.7094, KL: 32089.3105\n",
      "Epoch [20/500], Total Loss: 3196.3696, Likelihood: 0.6568, KL: 31957.1289\n",
      "Epoch [30/500], Total Loss: 3183.2568, Likelihood: 0.6359, KL: 31826.2070\n",
      "Epoch [40/500], Total Loss: 3170.2754, Likelihood: 0.6321, KL: 31696.4336\n",
      "Epoch [50/500], Total Loss: 3157.4128, Likelihood: 0.6494, KL: 31567.6328\n",
      "Epoch [60/500], Total Loss: 3144.6206, Likelihood: 0.6520, KL: 31439.6836\n",
      "Epoch [70/500], Total Loss: 3131.8677, Likelihood: 0.6230, KL: 31312.4453\n",
      "Epoch [80/500], Total Loss: 3119.1782, Likelihood: 0.5970, KL: 31185.8125\n",
      "Epoch [90/500], Total Loss: 3106.5012, Likelihood: 0.5313, KL: 31059.6992\n",
      "Epoch [100/500], Total Loss: 3093.9995, Likelihood: 0.5962, KL: 30934.0332\n",
      "Epoch [110/500], Total Loss: 3081.4648, Likelihood: 0.5889, KL: 30808.7598\n",
      "Epoch [120/500], Total Loss: 3068.9290, Likelihood: 0.5461, KL: 30683.8281\n",
      "Epoch [130/500], Total Loss: 3056.4890, Likelihood: 0.5694, KL: 30559.1953\n",
      "Epoch [140/500], Total Loss: 3044.0051, Likelihood: 0.5222, KL: 30434.8281\n",
      "Epoch [150/500], Total Loss: 3031.5635, Likelihood: 0.4934, KL: 30310.6992\n",
      "Epoch [160/500], Total Loss: 3019.1733, Likelihood: 0.4959, KL: 30186.7754\n",
      "Epoch [170/500], Total Loss: 3006.7747, Likelihood: 0.4705, KL: 30063.0410\n",
      "Epoch [180/500], Total Loss: 2994.4866, Likelihood: 0.5385, KL: 29939.4805\n",
      "Epoch [190/500], Total Loss: 2982.1106, Likelihood: 0.5024, KL: 29816.0801\n",
      "Epoch [200/500], Total Loss: 2969.7273, Likelihood: 0.4452, KL: 29692.8223\n",
      "Epoch [210/500], Total Loss: 2957.3931, Likelihood: 0.4229, KL: 29569.7012\n",
      "Epoch [220/500], Total Loss: 2945.0728, Likelihood: 0.4027, KL: 29446.6992\n",
      "Epoch [230/500], Total Loss: 2932.7539, Likelihood: 0.3728, KL: 29323.8105\n",
      "Epoch [240/500], Total Loss: 2920.4731, Likelihood: 0.3714, KL: 29201.0176\n",
      "Epoch [250/500], Total Loss: 2908.2231, Likelihood: 0.3923, KL: 29078.3086\n",
      "Epoch [260/500], Total Loss: 2895.9519, Likelihood: 0.3811, KL: 28955.7070\n",
      "Epoch [270/500], Total Loss: 2883.6953, Likelihood: 0.3768, KL: 28833.1855\n",
      "Epoch [280/500], Total Loss: 2871.4099, Likelihood: 0.3353, KL: 28710.7461\n",
      "Epoch [290/500], Total Loss: 2859.2275, Likelihood: 0.3889, KL: 28588.3848\n",
      "Epoch [300/500], Total Loss: 2846.9692, Likelihood: 0.3581, KL: 28466.1113\n",
      "Epoch [310/500], Total Loss: 2834.7400, Likelihood: 0.3487, KL: 28343.9121\n",
      "Epoch [320/500], Total Loss: 2822.5151, Likelihood: 0.3348, KL: 28221.8027\n",
      "Epoch [330/500], Total Loss: 2810.3147, Likelihood: 0.3367, KL: 28099.7793\n",
      "Epoch [340/500], Total Loss: 2798.1497, Likelihood: 0.3647, KL: 27977.8477\n",
      "Epoch [350/500], Total Loss: 2785.9634, Likelihood: 0.3638, KL: 27855.9961\n",
      "Epoch [360/500], Total Loss: 2773.7700, Likelihood: 0.3474, KL: 27734.2266\n",
      "Epoch [370/500], Total Loss: 2761.6101, Likelihood: 0.3553, KL: 27612.5488\n",
      "Epoch [380/500], Total Loss: 2749.4270, Likelihood: 0.3335, KL: 27490.9355\n",
      "Epoch [390/500], Total Loss: 2737.2764, Likelihood: 0.3369, KL: 27369.3945\n",
      "Epoch [400/500], Total Loss: 2725.1411, Likelihood: 0.3473, KL: 27247.9375\n",
      "Epoch [410/500], Total Loss: 2713.0515, Likelihood: 0.3951, KL: 27126.5645\n",
      "Epoch [420/500], Total Loss: 2700.8718, Likelihood: 0.3434, KL: 27005.2852\n",
      "Epoch [430/500], Total Loss: 2688.7754, Likelihood: 0.3665, KL: 26884.0879\n",
      "Epoch [440/500], Total Loss: 2676.6665, Likelihood: 0.3693, KL: 26762.9727\n",
      "Epoch [450/500], Total Loss: 2664.5310, Likelihood: 0.3356, KL: 26641.9551\n",
      "Epoch [460/500], Total Loss: 2652.4509, Likelihood: 0.3486, KL: 26521.0215\n",
      "Epoch [470/500], Total Loss: 2640.3459, Likelihood: 0.3291, KL: 26400.1680\n",
      "Epoch [480/500], Total Loss: 2628.2642, Likelihood: 0.3259, KL: 26279.3809\n",
      "Epoch [490/500], Total Loss: 2616.2083, Likelihood: 0.3389, KL: 26158.6934\n",
      "Epoch [500/500], Total Loss: 2604.1675, Likelihood: 0.3568, KL: 26038.1055\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nНачало обучения байесовской нейронной сети...\")\n",
    "train_bayesian_model(bayesian_model, X_train_tensor, y_train_tensor, epochs=500, kl_weight=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfc3075b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Оценка байесовской модели...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Оценка модели с учетом uncertainty\n",
    "print(\"\\nОценка байесовской модели...\")\n",
    "#y_pred_mean, y_pred_std = predict_with_uncertainty(bayesian_model, X_test_tensor, num_samples=100)\n",
    "bayesian_model.eval()\n",
    "predictions = []\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for _ in range(len(X_test_tensor)):\n",
    "        pred = bayesian_model(X_test_tensor, sample=True)\n",
    "        predictions.append(pred.numpy())\n",
    "    \n",
    "predictions = np.array(predictions)\n",
    "# Бинарные предсказания на основе среднего\n",
    "#y_pred_binary = (y_pred_mean > 0.5).astype(int)\n",
    "\n",
    "# Метрики\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "#mape_score = mean_absolute_percentage_error(y_test, y_pred_mean)\n",
    "#accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "#precision = precision_score(y_test, y_pred_binary, zero_division=0)\n",
    "#recall = recall_score(y_test, y_pred_binary, zero_division=0)\n",
    "#f1 = f1_score(y_test, y_pred_binary, zero_division=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"РЕЗУЛЬТАТЫ БАЙЕСОВСКОЙ НЕЙРОННОЙ СЕТИ\")\n",
    "print(\"=\"*50)\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "#print(f'MAPE: {mape_score:.4f}%')\n",
    "# print(f'Accuracy: {accuracy:.4f}')\n",
    "# print(f'Precision: {precision:.4f}')\n",
    "# print(f'Recall: {recall:.4f}')\n",
    "#print(f'F1-Score: {f1:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
