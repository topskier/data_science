{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c2d40131",
      "metadata": {
        "id": "c2d40131"
      },
      "source": [
        "https://colab.research.google.com/drive/1uMKT1vX88BZo21Ph0Gc-cDNpm7SkiK1G?authuser=0#scrollTo=LDZI4EpWGRz6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightautoml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IhVH6xotmhtj",
        "outputId": "2035d13e-b235-4061-d466-f51fda8ba3c1"
      },
      "id": "IhVH6xotmhtj",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightautoml\n",
            "  Downloading lightautoml-0.4.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: SQLAlchemy>=2.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.0.43)\n",
            "Collecting autowoe>=1.3.3 (from lightautoml)\n",
            "  Downloading autowoe-1.3.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting catboost>=0.26.1 (from lightautoml)\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting cmaes (from lightautoml)\n",
            "  Downloading cmaes-0.12.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: holidays in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.82)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (3.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.5.2)\n",
            "Collecting json2html (from lightautoml)\n",
            "  Downloading json2html-1.3.0.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lightgbm>=2.3 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (4.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from lightautoml) (3.5)\n",
            "Collecting numpy<2.0.0 (from lightautoml)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna (from lightautoml)\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.2.2)\n",
            "Collecting poetry-core<2.0.0,>=1.0.0 (from lightautoml)\n",
            "  Downloading poetry_core-1.9.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from lightautoml) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.16.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.13.2)\n",
            "Collecting statsmodels<=0.14.0 (from lightautoml)\n",
            "  Downloading statsmodels-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lightautoml) (4.67.1)\n",
            "Collecting xgboost<3.0.0,>=2.0.0 (from lightautoml)\n",
            "  Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting StrEnum<0.5.0,>=0.4.7 (from autowoe>=1.3.3->lightautoml)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (3.10.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (8.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (2025.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (8.2.3)\n",
            "Collecting sphinx-rtd-theme (from autowoe>=1.3.3->lightautoml)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->lightautoml) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->lightautoml) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->lightautoml) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy>=2.0->lightautoml) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy>=2.0->lightautoml) (4.15.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from statsmodels<=0.14.0->lightautoml) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels<=0.14.0->lightautoml) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (1.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->lightautoml) (3.0.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->lightautoml) (1.16.5)\n",
            "Collecting colorlog (from optuna->lightautoml)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->lightautoml) (1.3.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (3.2.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->lightautoml) (1.3.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost>=0.26.1->lightautoml) (8.5.0)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (2.19.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.32.4)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (3.1.0)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->autowoe>=1.3.3->lightautoml)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx->autowoe>=1.3.3->lightautoml) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx->autowoe>=1.3.3->lightautoml) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx->autowoe>=1.3.3->lightautoml) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx->autowoe>=1.3.3->lightautoml) (2025.10.5)\n",
            "Downloading lightautoml-0.4.1-py3-none-any.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.0/399.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autowoe-1.3.4-py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.1/216.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading poetry_core-1.9.1-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsmodels-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl (223.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmaes-0.12.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: json2html\n",
            "  Building wheel for json2html (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7591 sha256=2e75c02f73ffc47c9ed501207d921600921c300317e6a4b1e6a9065bfdaf2e27\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/96/d0/3cfff4cc9a9e307cfc2b8fe4846c56d714b78bbe5f6da211a5\n",
            "Successfully built json2html\n",
            "Installing collected packages: StrEnum, json2html, poetry-core, numpy, colorlog, cmaes, xgboost, statsmodels, sphinxcontrib-jquery, optuna, sphinx-rtd-theme, catboost, autowoe, lightautoml\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 3.0.5\n",
            "    Uninstalling xgboost-3.0.5:\n",
            "      Successfully uninstalled xgboost-3.0.5\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.14.5\n",
            "    Uninstalling statsmodels-0.14.5:\n",
            "      Successfully uninstalled statsmodels-0.14.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed StrEnum-0.4.15 autowoe-1.3.4 catboost-1.2.8 cmaes-0.12.0 colorlog-6.9.0 json2html-1.3.0 lightautoml-0.4.1 numpy-1.26.4 optuna-4.5.0 poetry-core-1.9.1 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1 statsmodels-0.14.0 xgboost-2.1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "sphinxcontrib"
                ]
              },
              "id": "e1ddce15162a48caa9e7110cb2be9823"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "699ad07d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "699ad07d",
        "outputId": "164ae76a-abf8-454f-dc18-568a9f6072a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lightautoml.utils.installation:'nlp' extra dependency package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
            "WARNING:lightautoml.utils.installation:'nlp' extra dependency package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
            "/usr/local/lib/python3.12/dist-packages/lightautoml/transformers/text.py:22: UserWarning: 'gensim' - package isn't installed\n",
            "  warnings.warn(\"'gensim' - package isn't installed\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightautoml.tasks import Task\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "from lightautoml.report.report_deco import ReportDeco\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "34b66199",
      "metadata": {
        "id": "34b66199"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"Загрузка и предобработка данных аналогично NN_deepseek\"\"\"\n",
        "    print(\"Загрузка данных...\")\n",
        "    data = pd.read_csv(file_path, sep=\";\", index_col=False)\n",
        "\n",
        "    # Создание целевой переменной: 1 если N_claims_year > 1, иначе 0\n",
        "    data['claim_prob'] = (data['N_claims_year'] > 1).astype(int)\n",
        "\n",
        "    # Удаление ненужных столбцов\n",
        "    cols_to_drop = ['ID', 'Date_start_contract', 'Date_last_renewal', 'Date_next_renewal',\n",
        "                    'Date_lapse', 'N_claims_year', 'Cost_claims_year', 'N_claims_history',\n",
        "                    'R_Claims_history']\n",
        "    data = data.drop(columns=cols_to_drop)\n",
        "\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f7aa720a",
      "metadata": {
        "id": "f7aa720a"
      },
      "outputs": [],
      "source": [
        "def process_dates_and_features(data):\n",
        "    \"\"\"Обработка дат и создание новых признаков\"\"\"\n",
        "    print(\"Обработка дат и признаков...\")\n",
        "\n",
        "    # Обработка датовых колонок\n",
        "    date_columns = ['Date_birth', 'Date_driving_licence']\n",
        "    existing_date_columns = [col for col in date_columns if col in data.columns]\n",
        "\n",
        "    if not existing_date_columns:\n",
        "        print(\"Предупреждение: Датовые колонки не найдены в DataFrame.\")\n",
        "    else:\n",
        "        for col in existing_date_columns:\n",
        "            data[col] = pd.to_datetime(data[col], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "        # Извлечение числовых признаков из дат\n",
        "        reference_date = pd.to_datetime('2019-12-31')\n",
        "\n",
        "        if 'Date_birth' in data.columns:\n",
        "            data['Age'] = (reference_date - data['Date_birth']).dt.days // 365\n",
        "\n",
        "        if 'Date_driving_licence' in data.columns:\n",
        "            data['Driving_experience'] = (reference_date - data['Date_driving_licence']).dt.days // 365\n",
        "\n",
        "    # Удаление исходных датовых колонок\n",
        "    data = data.drop(columns=date_columns, errors='ignore')\n",
        "\n",
        "    # Обработка категориальных переменных\n",
        "    categorical_cols = ['Type_fuel']\n",
        "    for col in categorical_cols:\n",
        "        if col in data.columns:\n",
        "            le = LabelEncoder()\n",
        "            data[col] = le.fit_transform(data[col].astype(str))\n",
        "\n",
        "    # Убедиться, что все данные числовые\n",
        "    data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # Обработка пропущенных значений\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    data_imputed = imputer.fit_transform(data)\n",
        "    data = pd.DataFrame(data_imputed, columns=data.columns)\n",
        "\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7bc47c86",
      "metadata": {
        "id": "7bc47c86"
      },
      "outputs": [],
      "source": [
        "def train_automl_model(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"Обучение AutoML модели для бинарной классификации\"\"\"\n",
        "    print(\"Настройка AutoML...\")\n",
        "\n",
        "    # Объединение признаков и целевой переменной для LightAutoML\n",
        "    train_data = pd.concat([X_train, y_train], axis=1)\n",
        "    test_data = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "    # Настройка AutoML для бинарной классификации\n",
        "    TARGET_NAME = 'claim_prob'\n",
        "    task = Task('binary')\n",
        "\n",
        "    automl = TabularAutoML(\n",
        "        task=task,\n",
        "        timeout=3600,  # Максимальное время работы модели (секунды)\n",
        "        cpu_limit=4,   # Количество CPU\n",
        "        memory_limit=16  # Ограничение памяти (ГБ)\n",
        "    )\n",
        "\n",
        "    # Обертка для генерации отчетов\n",
        "    automl_with_report = ReportDeco(output_path='AutoML_classification_report.html')(automl)\n",
        "\n",
        "    # Определяем роли переменных\n",
        "    roles = {'target': TARGET_NAME}\n",
        "\n",
        "    print(\"Обучение AutoML модели...\")\n",
        "    # Обучение модели\n",
        "    oof_pred = automl_with_report.fit_predict(\n",
        "        train_data=train_data,\n",
        "        roles=roles,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return automl, test_data, train_data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(automl, test_data, train_data, y_test, y_train):\n",
        "    \"\"\"Оценка модели и вывод результатов\"\"\"\n",
        "    print(\"Оценка модели...\")\n",
        "\n",
        "    # Предсказание на тестовых данных\n",
        "    test_pred = automl.predict(test_data)\n",
        "    test_proba = test_pred.data[:, 0]  # Вероятности класса 1\n",
        "\n",
        "    # Предсказание на тренировочных данных\n",
        "    train_pred = automl.predict(train_data)\n",
        "    train_proba = train_pred.data[:, 0]\n",
        "\n",
        "    # Метрики\n",
        "    roc_auc_test = roc_auc_score(y_test, test_proba)\n",
        "    mae_test = mean_absolute_error(y_test, test_proba)\n",
        "    roc_auc_train = roc_auc_score(y_train, train_proba)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"РЕЗУЛЬТАТЫ AUTOML ДЛЯ БИНАРНОЙ КЛАССИФИКАЦИИ\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"ROC-AUC на тестовых данных: {roc_auc_test:.4f}\")\n",
        "    print(f\"MAE на тестовых данных: {mae_test:.4f}\")\n",
        "    print(f\"ROC-AUC на тренировочных данных: {roc_auc_train:.4f}\")\n",
        "\n",
        "    # Анализ важности признаков\n",
        "    try:\n",
        "        feature_scores = automl.get_feature_scores()\n",
        "        feature_scores = feature_scores.sort_values('importance', ascending=False)\n",
        "\n",
        "        print(\"\\nТоп-10 важных признаков:\")\n",
        "        print(\"-\" * 30)\n",
        "        for i, (feature, importance) in enumerate(feature_scores.head(10)['importance'].items(), 1):\n",
        "            print(f\"{i:2d}. {feature:<25} {importance:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nНе удалось получить важность признаков: {e}\")\n",
        "\n",
        "    return test_proba, train_proba\n",
        "\n"
      ],
      "metadata": {
        "id": "WvoFRwUImOTH"
      },
      "id": "WvoFRwUImOTH",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Основная функция\"\"\"\n",
        "    file_path = 'sample_data/vehicle_ins_data_1.csv'\n",
        "\n",
        "    try:\n",
        "        # 1. Загрузка и предобработка данных\n",
        "        data = load_and_preprocess_data(file_path)\n",
        "\n",
        "        # 2. Обработка признаков\n",
        "        data = process_dates_and_features(data)\n",
        "\n",
        "        # 3. Разделение на обучающую и тестовую выборки\n",
        "        print(\"Разделение данных на train/test...\")\n",
        "        X = data.drop(columns=['claim_prob'])\n",
        "        y = data['claim_prob']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        print(f\"Размеры данных: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "\n",
        "        # 4. Обучение AutoML модели\n",
        "        automl, test_data, train_data = train_automl_model(X_train, y_train, X_test, y_test)\n",
        "\n",
        "        # 5. Оценка модели\n",
        "        test_proba, train_proba = evaluate_model(automl, test_data, train_data, y_test, y_train)\n",
        "\n",
        "        print(\"\\nAutoML обучение завершено успешно!\")\n",
        "        print(\"Отчет сохранен в файл: AutoML_classification_report.html\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Произошла ошибка: {e}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMX0LhwmQrk",
        "outputId": "bb4c4f61-3276-447c-bdc4-4de762fafe8a"
      },
      "id": "iQMX0LhwmQrk",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных...\n",
            "Обработка дат и признаков...\n",
            "Разделение данных на train/test...\n",
            "Размеры данных: Train (84444, 21), Test (21111, 21)\n",
            "Настройка AutoML...\n",
            "Обучение AutoML модели...\n",
            "[08:49:52] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:49:52] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lightautoml.utils.timer:Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:49:52] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:49:52] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:49:52] - time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:49:52] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:49:52] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:49:52] \u001b[1mTrain data shape: (84444, 22)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (84444, 22)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:50:12] Layer \u001b[1m1\u001b[0m train process start. Time left 3580.04 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 3580.04 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:50:16] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [0, 1, 2, 3], 'embed_sizes': array([ 6,  7, 41,  5], dtype=int32), 'data_size': 33}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7097021750472585\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7196066607452475\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7227212029102249\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7267223161154084\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7272448658174254\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7270236841902568\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7270236841902568\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6903823288203796\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7007490419584305\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7041738100035229\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7088637645226454\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7096931956245279\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7105156945309842\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7105156945309842\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7105111338760985\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6976998009170393\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7053471294389309\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7082331962571625\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7130239338754146\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.714037196294762\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7147799893424817\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7147799893424817\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7147800298592027\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7135615502475409\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7135615502475409\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7036090431376667\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7124738788699141\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7151527634348586\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.718301115247058\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7187516206688436\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7191420803099755\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7191420803099755\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7191426272857102\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7191380894129484\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7191380894129484\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.697622466162286\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7066422280642968\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7096955330426891\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7143597465245028\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7154710380466633\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7169807947370246\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7169807947370246\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7169812406969217\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7169814636768704\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7169814636768704\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.7169814636768704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:50:27] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7175081007389594\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7175081007389594\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:50:27] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:50:27] Time left 3564.64 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 3564.64 secs\n",
            "\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.755722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763863\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.767304\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.767864\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.768939\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.768903\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.768239\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[526]\tvalid's auc: 0.769571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:50:38] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:50:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.03, 'num_leaves': 64, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 1200, 'early_stopping_rounds': 200, 'random_state': 42, 'verbose_eval': 100}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.753569\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.759639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.761393\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.762768\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.76441\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.765309\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.766567\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.768071\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.768844\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.769739\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.769216\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.76993\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1175]\tvalid's auc: 0.770233\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.731039\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736508\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.738903\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.741748\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.742371\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.743089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.744194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.744254\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.744634\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.744372\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.74458\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[936]\tvalid's auc: 0.74509\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.741286\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.746909\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.749013\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.752437\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.75314\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.754468\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.754424\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.755159\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.755942\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.756617\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.757549\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.757747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1193]\tvalid's auc: 0.75789\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.741275\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.747686\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.751341\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.754169\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.756114\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.758357\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.759592\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.760682\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.761211\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.762247\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.762713\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.762759\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1116]\tvalid's auc: 0.762861\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.736806\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.742161\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.745729\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.748225\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.749256\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.749625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.750795\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.75116\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.751029\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.751789\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.751772\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.752089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1064]\tvalid's auc: 0.752396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:52:47] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7577449843130675\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7577449843130675\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:52:47] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:52:47] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
            "Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-5bbba602-efea-453c-a853-8376c83d67d5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763966\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.768991\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.771975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.774287\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.775377\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.776611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.777066\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.777115\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.776622\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[769]\tvalid's auc: 0.777327\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.7773267954487502 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.7773267954487502 in 0:00:36.227882\n",
            "Optimization Progress:   1%|          | 1/101 [00:36<1:00:24, 36.24s/it, best_trial=0, best_value=0.777]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.757394\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.766647\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.77076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.772786\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.773715\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.774678\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.775269\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.775833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.775055\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.774222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[805]\tvalid's auc: 0.77599\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.7759903006018848 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored 0.7759903006018848 in 0:00:37.116979\n",
            "Optimization Progress:   2%|▏         | 2/101 [01:13<1:00:39, 36.77s/it, best_trial=0, best_value=0.777]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.754526\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.759306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.762888\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.763871\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.76596\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.767574\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.768818\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.769825\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.769627\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.7698\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[810]\tvalid's auc: 0.770189\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.7701889651610561 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored 0.7701889651610561 in 0:00:22.569641\n",
            "Optimization Progress:   3%|▎         | 3/101 [01:35<49:28, 30.29s/it, best_trial=0, best_value=0.777]  INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756337\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763684\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.766551\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.767674\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.768672\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.769706\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.770949\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.771823\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.772833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.773223\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.773814\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.774392\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1200]\tvalid's auc: 0.774392\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.77439238901697 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored 0.77439238901697 in 0:00:25.590181\n",
            "Optimization Progress:   4%|▍         | 4/101 [02:01<45:58, 28.44s/it, best_trial=0, best_value=0.777]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.759131\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.764882\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.767468\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.769521\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.770302\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.770929\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.771719\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.771546\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.771751\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.772194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.772401\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.772405\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1121]\tvalid's auc: 0.772545\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.7725449589358635 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored 0.7725449589358635 in 0:00:49.926389\n",
            "Optimization Progress:   5%|▍         | 5/101 [02:51<57:54, 36.19s/it, best_trial=0, best_value=0.777]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.749798\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75515\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.756928\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.757209\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.757748\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.757794\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.758367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.759364\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.758963\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.758795\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.759356\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.759404\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1125]\tvalid's auc: 0.759748\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.7597479842918884 and parameters: {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored 0.7597479842918884 in 0:00:27.109968\n",
            "Optimization Progress:   6%|▌         | 6/101 [03:18<52:25, 33.11s/it, best_trial=0, best_value=0.777]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.752424\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.757443\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.759521\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.761254\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.762303\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.763117\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.764259\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.764263\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.765308\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.765599\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.766114\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.767275\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1197]\tvalid's auc: 0.767298\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.7672981991291379 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored 0.7672981991291379 in 0:00:20.439921\n",
            "Optimization Progress:   7%|▋         | 7/101 [03:39<45:23, 28.97s/it, best_trial=0, best_value=0.777]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756244\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.76539\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.770655\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.772048\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.772829\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.772921\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.773541\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.774339\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.774335\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.775524\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.775363\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.776193\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1198]\tvalid's auc: 0.776223\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.7762229142706337 and parameters: {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored 0.7762229142706337 in 0:00:40.421316\n",
            "Optimization Progress:   8%|▊         | 8/101 [04:19<50:33, 32.62s/it, best_trial=0, best_value=0.777]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.753256\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.758211\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.761141\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.762727\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.763983\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.765099\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.766606\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.767845\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.768595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.769493\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.769861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.770203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
            "[1156]\tvalid's auc: 0.770397\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.7703967688672266 and parameters: {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored 0.7703967688672266 in 0:00:24.927648\n",
            "Optimization Progress:   9%|▉         | 9/101 [04:44<46:20, 30.22s/it, best_trial=0, best_value=0.777]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.757296\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.764371\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.766039\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.76795\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.768686\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.76932\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.768866\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.769548\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[662]\tvalid's auc: 0.769792\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.7697922084555758 and parameters: {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06}. Best is trial 0 with value: 0.7773267954487502.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored 0.7697922084555758 in 0:00:36.519533\n",
            "Optimization Progress:  10%|▉         | 10/101 [05:20<48:41, 32.10s/it, best_trial=0, best_value=0.777]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:58:08] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
            " achieve 0.7773 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:58:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 244, 'feature_fraction': 0.6872700594236812, 'bagging_fraction': 0.8659969709057025, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'verbose_eval': 100, 'min_sum_hessian_in_leaf': 0.24810409748678125}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.762908\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.768389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.771422\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.771584\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.773956\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.775318\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.774822\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[612]\tvalid's auc: 0.77601\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.742616\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.749542\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.751416\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.752726\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.753156\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[445]\tvalid's auc: 0.753962\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.752449\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75832\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.760139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[294]\tvalid's auc: 0.760416\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.752973\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.761247\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.764066\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.76388\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[360]\tvalid's auc: 0.76537\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.74253\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.746525\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.750031\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.752777\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.752995\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[425]\tvalid's auc: 0.753568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:59:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7581702641207452\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7581702641207452\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:59:46] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:59:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 1500, 'learning_rate': 0.045, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5623854\tbest: 0.5623854 (0)\ttotal: 65ms\tremaining: 1m 37s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7457613\tbest: 0.7457613 (100)\ttotal: 1.75s\tremaining: 24.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7507908\tbest: 0.7507908 (200)\ttotal: 3.41s\tremaining: 22s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7526318\tbest: 0.7526543 (299)\ttotal: 5.05s\tremaining: 20.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7545605\tbest: 0.7547406 (385)\ttotal: 6.72s\tremaining: 18.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7557948\tbest: 0.7557948 (500)\ttotal: 8.38s\tremaining: 16.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7569004\tbest: 0.7569148 (579)\ttotal: 11.4s\tremaining: 17.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7572300\tbest: 0.7574022 (687)\ttotal: 13.1s\tremaining: 15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7577314\tbest: 0.7578448 (771)\ttotal: 14.8s\tremaining: 12.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7576743\tbest: 0.7580155 (849)\ttotal: 16.5s\tremaining: 11s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7583161\tbest: 0.7585492 (977)\ttotal: 18.2s\tremaining: 9.07s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7588796\tbest: 0.7588796 (1100)\ttotal: 19.9s\tremaining: 7.21s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7595131\tbest: 0.7596564 (1195)\ttotal: 22.2s\tremaining: 5.52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7598067\tbest: 0.7600655 (1275)\ttotal: 24.6s\tremaining: 3.77s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7606697\tbest: 0.7606697 (1400)\ttotal: 26.3s\tremaining: 1.86s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1499:\ttest: 0.7610560\tbest: 0.7611083 (1496)\ttotal: 28s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7611082959\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1496\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1497 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5468416\tbest: 0.5468416 (0)\ttotal: 18.8ms\tremaining: 28.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7253191\tbest: 0.7253191 (100)\ttotal: 1.69s\tremaining: 23.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7292407\tbest: 0.7292472 (199)\ttotal: 3.37s\tremaining: 21.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7314463\tbest: 0.7314463 (300)\ttotal: 5.02s\tremaining: 20s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7324575\tbest: 0.7324982 (391)\ttotal: 8.12s\tremaining: 22.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7334854\tbest: 0.7334854 (500)\ttotal: 9.8s\tremaining: 19.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7353663\tbest: 0.7353719 (599)\ttotal: 11.5s\tremaining: 17.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7359950\tbest: 0.7359950 (700)\ttotal: 13.2s\tremaining: 15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7370375\tbest: 0.7370375 (800)\ttotal: 14.9s\tremaining: 13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7372225\tbest: 0.7372627 (870)\ttotal: 16.6s\tremaining: 11.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7369913\tbest: 0.7374442 (975)\ttotal: 19.1s\tremaining: 9.55s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7374441928\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 975\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 976 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5618181\tbest: 0.5618181 (0)\ttotal: 23.9ms\tremaining: 35.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7302736\tbest: 0.7303344 (99)\ttotal: 1.72s\tremaining: 23.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7338363\tbest: 0.7338363 (200)\ttotal: 3.46s\tremaining: 22.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7358395\tbest: 0.7358980 (288)\ttotal: 5.16s\tremaining: 20.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7374548\tbest: 0.7375125 (391)\ttotal: 6.85s\tremaining: 18.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7388977\tbest: 0.7389101 (497)\ttotal: 8.59s\tremaining: 17.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7395049\tbest: 0.7395049 (600)\ttotal: 11.7s\tremaining: 17.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7402292\tbest: 0.7403958 (693)\ttotal: 13.3s\tremaining: 15.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7400719\tbest: 0.7407084 (749)\ttotal: 15s\tremaining: 13.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7409543\tbest: 0.7411783 (893)\ttotal: 16.7s\tremaining: 11.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7414033\tbest: 0.7415690 (986)\ttotal: 18.5s\tremaining: 9.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7415689565\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 986\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 987 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5615509\tbest: 0.5615509 (0)\ttotal: 17.2ms\tremaining: 25.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7311337\tbest: 0.7311337 (100)\ttotal: 2.13s\tremaining: 29.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7350076\tbest: 0.7350438 (198)\ttotal: 4.91s\tremaining: 31.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7368824\tbest: 0.7369310 (299)\ttotal: 6.63s\tremaining: 26.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7382326\tbest: 0.7382326 (400)\ttotal: 8.34s\tremaining: 22.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7393707\tbest: 0.7393707 (500)\ttotal: 10s\tremaining: 20s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7398161\tbest: 0.7398451 (592)\ttotal: 11.7s\tremaining: 17.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7399833\tbest: 0.7406295 (645)\ttotal: 13.5s\tremaining: 15.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7406294548\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 646 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5924670\tbest: 0.5924670 (0)\ttotal: 26.8ms\tremaining: 40.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7305003\tbest: 0.7305765 (99)\ttotal: 2.53s\tremaining: 35s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7350691\tbest: 0.7350691 (200)\ttotal: 4.23s\tremaining: 27.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7373315\tbest: 0.7373315 (300)\ttotal: 5.9s\tremaining: 23.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7387945\tbest: 0.7387945 (400)\ttotal: 7.55s\tremaining: 20.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7398191\tbest: 0.7399440 (476)\ttotal: 9.25s\tremaining: 18.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7404309\tbest: 0.7409324 (569)\ttotal: 10.9s\tremaining: 16.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7409323684\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 569\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 570 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:01:24] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7442574256136787\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7442574256136787\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:01:24] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:01:24] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
            "Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-b8d208f6-4f90-4d16-8e20-432c95a6bc8f\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5619450\tbest: 0.5619450 (0)\ttotal: 46.4ms\tremaining: 1m 9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430943\tbest: 0.7430989 (98)\ttotal: 1.85s\tremaining: 25.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7486564\tbest: 0.7486564 (200)\ttotal: 3.36s\tremaining: 21.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7512838\tbest: 0.7512922 (293)\ttotal: 4.89s\tremaining: 19.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7529125\tbest: 0.7529125 (400)\ttotal: 6.45s\tremaining: 17.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7548672\tbest: 0.7548672 (500)\ttotal: 7.96s\tremaining: 15.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7560193\tbest: 0.7560445 (592)\ttotal: 9.5s\tremaining: 14.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7565464\tbest: 0.7565756 (691)\ttotal: 11.7s\tremaining: 13.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7576345\tbest: 0.7576704 (799)\ttotal: 14s\tremaining: 12.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7585477\tbest: 0.7585477 (900)\ttotal: 15.5s\tremaining: 10.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7594537\tbest: 0.7594575 (995)\ttotal: 17s\tremaining: 8.49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7599271\tbest: 0.7599691 (1092)\ttotal: 18.6s\tremaining: 6.72s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7603081\tbest: 0.7603242 (1195)\ttotal: 20.1s\tremaining: 5.01s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7606295\tbest: 0.7606538 (1264)\ttotal: 21.7s\tremaining: 3.31s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7611526\tbest: 0.7611526 (1400)\ttotal: 23.4s\tremaining: 1.66s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1499:\ttest: 0.7614059\tbest: 0.7614400 (1497)\ttotal: 26.2s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7614399873\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1497\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1498 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.7614400075240672 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15} scored 0.7614400075240672 in 0:00:26.646898\n",
            "Optimization Progress:   1%|          | 1/101 [00:26<44:26, 26.66s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5623854\tbest: 0.5623854 (0)\ttotal: 18ms\tremaining: 26.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7439288\tbest: 0.7439288 (100)\ttotal: 1.71s\tremaining: 23.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7492043\tbest: 0.7492045 (199)\ttotal: 3.35s\tremaining: 21.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7514912\tbest: 0.7520437 (293)\ttotal: 5.02s\tremaining: 20s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7531020\tbest: 0.7532434 (385)\ttotal: 6.66s\tremaining: 18.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7546397\tbest: 0.7546397 (500)\ttotal: 8.32s\tremaining: 16.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7545469\tbest: 0.7552410 (542)\ttotal: 11.3s\tremaining: 16.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7568198\tbest: 0.7568198 (700)\ttotal: 13.2s\tremaining: 15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7579357\tbest: 0.7579603 (799)\ttotal: 14.8s\tremaining: 12.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7585030\tbest: 0.7587851 (889)\ttotal: 16.5s\tremaining: 11s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.758785078\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 890 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.7587850780236838 and parameters: {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4} scored 0.7587850780236838 in 0:00:18.209020\n",
            "Optimization Progress:   2%|▏         | 2/101 [00:44<35:48, 21.70s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5529706\tbest: 0.5529706 (0)\ttotal: 14.5ms\tremaining: 21.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7391066\tbest: 0.7391066 (100)\ttotal: 1.38s\tremaining: 19.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7442614\tbest: 0.7442614 (200)\ttotal: 2.67s\tremaining: 17.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7472305\tbest: 0.7472385 (299)\ttotal: 4.75s\tremaining: 18.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7491952\tbest: 0.7492152 (398)\ttotal: 6.79s\tremaining: 18.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7504990\tbest: 0.7504990 (500)\ttotal: 8.09s\tremaining: 16.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7514749\tbest: 0.7515020 (595)\ttotal: 9.38s\tremaining: 14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7523797\tbest: 0.7523797 (700)\ttotal: 10.7s\tremaining: 12.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7532228\tbest: 0.7532228 (800)\ttotal: 12s\tremaining: 10.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7538234\tbest: 0.7538875 (892)\ttotal: 13.3s\tremaining: 8.84s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7546328\tbest: 0.7546343 (999)\ttotal: 14.6s\tremaining: 7.28s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7556790\tbest: 0.7556790 (1100)\ttotal: 15.9s\tremaining: 5.76s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7562409\tbest: 0.7562409 (1200)\ttotal: 18.7s\tremaining: 4.64s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7562043\tbest: 0.7563740 (1283)\ttotal: 19.9s\tremaining: 3.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7564418\tbest: 0.7564745 (1396)\ttotal: 21.2s\tremaining: 1.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1499:\ttest: 0.7570308\tbest: 0.7570572 (1483)\ttotal: 22.6s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7570571776\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1483\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1484 iterations.\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.7570571776397375 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13} scored 0.7570571776397375 in 0:00:22.862383\n",
            "Optimization Progress:   3%|▎         | 3/101 [01:07<36:19, 22.24s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5820665\tbest: 0.5820665 (0)\ttotal: 19.2ms\tremaining: 28.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7458775\tbest: 0.7459933 (97)\ttotal: 1.91s\tremaining: 26.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7512797\tbest: 0.7512809 (188)\ttotal: 3.8s\tremaining: 24.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7544068\tbest: 0.7544068 (300)\ttotal: 5.71s\tremaining: 22.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7578362\tbest: 0.7578984 (399)\ttotal: 9.01s\tremaining: 24.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7589517\tbest: 0.7592708 (497)\ttotal: 10.9s\tremaining: 21.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7594198\tbest: 0.7597133 (535)\ttotal: 12.8s\tremaining: 19.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7605915\tbest: 0.7607450 (677)\ttotal: 14.7s\tremaining: 16.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.760744984\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 677\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 678 iterations.\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.760744983989061 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20} scored 0.760744983989061 in 0:00:16.446453\n",
            "Optimization Progress:   4%|▍         | 4/101 [01:24<32:15, 19.95s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5944390\tbest: 0.5944390 (0)\ttotal: 21.2ms\tremaining: 31.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7478285\tbest: 0.7482507 (84)\ttotal: 2.75s\tremaining: 38.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7496762\tbest: 0.7506732 (194)\ttotal: 5.74s\tremaining: 37.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7498805\tbest: 0.7513028 (273)\ttotal: 7.83s\tremaining: 31.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7513027865\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.7513027865398656 and parameters: {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.7513027865398656 in 0:00:09.647927\n",
            "Optimization Progress:   5%|▍         | 5/101 [01:33<25:59, 16.24s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5529706\tbest: 0.5529706 (0)\ttotal: 17.6ms\tremaining: 26.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7396060\tbest: 0.7396060 (100)\ttotal: 1.34s\tremaining: 18.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7448450\tbest: 0.7448450 (200)\ttotal: 2.64s\tremaining: 17.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7475426\tbest: 0.7475426 (300)\ttotal: 3.98s\tremaining: 15.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7495106\tbest: 0.7495206 (399)\ttotal: 6.22s\tremaining: 17s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7509580\tbest: 0.7509967 (498)\ttotal: 8.02s\tremaining: 16s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7519077\tbest: 0.7519077 (600)\ttotal: 9.31s\tremaining: 13.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7527193\tbest: 0.7527699 (695)\ttotal: 10.6s\tremaining: 12.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7534641\tbest: 0.7534641 (800)\ttotal: 11.9s\tremaining: 10.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7541457\tbest: 0.7541457 (900)\ttotal: 13.2s\tremaining: 8.74s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7547977\tbest: 0.7547977 (1000)\ttotal: 14.5s\tremaining: 7.21s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7549632\tbest: 0.7550077 (1093)\ttotal: 15.7s\tremaining: 5.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7551016\tbest: 0.7552415 (1173)\ttotal: 17s\tremaining: 4.24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7554512\tbest: 0.7554566 (1299)\ttotal: 19.7s\tremaining: 3.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7553741\tbest: 0.7555333 (1307)\ttotal: 21s\tremaining: 1.48s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.75553325\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1307\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1308 iterations.\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.7555332500118577 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11} scored 0.7555332500118577 in 0:00:21.391982\n",
            "Optimization Progress:   6%|▌         | 6/101 [01:55<28:29, 18.00s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5623854\tbest: 0.5623854 (0)\ttotal: 17.9ms\tremaining: 26.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7443454\tbest: 0.7444535 (98)\ttotal: 1.7s\tremaining: 23.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7497556\tbest: 0.7497556 (200)\ttotal: 3.39s\tremaining: 21.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7516255\tbest: 0.7516446 (299)\ttotal: 5.08s\tremaining: 20.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7547178\tbest: 0.7547178 (400)\ttotal: 6.74s\tremaining: 18.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7556494\tbest: 0.7556494 (500)\ttotal: 8.75s\tremaining: 17.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7563617\tbest: 0.7563617 (600)\ttotal: 11.6s\tremaining: 17.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7571664\tbest: 0.7571664 (700)\ttotal: 13.3s\tremaining: 15.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7578457\tbest: 0.7578744 (799)\ttotal: 15s\tremaining: 13.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7579495\tbest: 0.7586722 (837)\ttotal: 16.7s\tremaining: 11.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7586721765\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 837\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 838 iterations.\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.7586721764782907 and parameters: {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13} scored 0.7586721764782907 in 0:00:17.570673\n",
            "Optimization Progress:   7%|▋         | 7/101 [02:12<27:59, 17.86s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5529706\tbest: 0.5529706 (0)\ttotal: 14.8ms\tremaining: 22.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7386686\tbest: 0.7387203 (98)\ttotal: 1.35s\tremaining: 18.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7449080\tbest: 0.7449417 (198)\ttotal: 2.63s\tremaining: 17s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7483313\tbest: 0.7483313 (300)\ttotal: 5.03s\tremaining: 20s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7497897\tbest: 0.7498147 (395)\ttotal: 6.65s\tremaining: 18.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7510286\tbest: 0.7510511 (499)\ttotal: 7.95s\tremaining: 15.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7521173\tbest: 0.7521640 (597)\ttotal: 9.24s\tremaining: 13.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7529387\tbest: 0.7529798 (693)\ttotal: 10.5s\tremaining: 12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7537703\tbest: 0.7537803 (787)\ttotal: 11.8s\tremaining: 10.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7545083\tbest: 0.7545083 (900)\ttotal: 13.1s\tremaining: 8.69s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7549157\tbest: 0.7549520 (999)\ttotal: 14.4s\tremaining: 7.17s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7554095\tbest: 0.7554095 (1100)\ttotal: 15.8s\tremaining: 5.74s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7559118\tbest: 0.7559118 (1200)\ttotal: 18.4s\tremaining: 4.58s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7566982\tbest: 0.7566982 (1300)\ttotal: 19.7s\tremaining: 3.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7569928\tbest: 0.7569928 (1400)\ttotal: 21s\tremaining: 1.48s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1499:\ttest: 0.7575143\tbest: 0.7575605 (1496)\ttotal: 22.2s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7575605118\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1496\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1497 iterations.\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.7575605117825026 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8} scored 0.7575605117825026 in 0:00:22.530435\n",
            "Optimization Progress:   8%|▊         | 8/101 [02:35<29:59, 19.35s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5623854\tbest: 0.5623854 (0)\ttotal: 18.2ms\tremaining: 27.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7458170\tbest: 0.7458256 (99)\ttotal: 1.73s\tremaining: 24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7495401\tbest: 0.7495401 (200)\ttotal: 3.45s\tremaining: 22.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7518297\tbest: 0.7519727 (290)\ttotal: 5.15s\tremaining: 20.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7545459\tbest: 0.7545984 (397)\ttotal: 8.27s\tremaining: 22.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7558430\tbest: 0.7558689 (498)\ttotal: 9.96s\tremaining: 19.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7573823\tbest: 0.7574059 (596)\ttotal: 11.6s\tremaining: 17.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7584863\tbest: 0.7585320 (698)\ttotal: 13.4s\tremaining: 15.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7594954\tbest: 0.7594954 (800)\ttotal: 15.1s\tremaining: 13.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7603184\tbest: 0.7604549 (887)\ttotal: 16.8s\tremaining: 11.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7607336\tbest: 0.7612504 (985)\ttotal: 19s\tremaining: 9.46s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7612503856\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 985\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 986 iterations.\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.7612503856287076 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4} scored 0.7612503856287076 in 0:00:21.646572\n",
            "Optimization Progress:   9%|▉         | 9/101 [02:57<30:46, 20.07s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5623854\tbest: 0.5623854 (0)\ttotal: 17.8ms\tremaining: 26.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7443383\tbest: 0.7443383 (100)\ttotal: 1.69s\tremaining: 23.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7487544\tbest: 0.7488003 (197)\ttotal: 3.39s\tremaining: 21.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7510969\tbest: 0.7511320 (293)\ttotal: 5.11s\tremaining: 20.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7532188\tbest: 0.7532188 (400)\ttotal: 6.78s\tremaining: 18.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7538022\tbest: 0.7538765 (498)\ttotal: 8.47s\tremaining: 16.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7547893\tbest: 0.7551640 (574)\ttotal: 11.7s\tremaining: 17.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7563029\tbest: 0.7563029 (700)\ttotal: 13.4s\tremaining: 15.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7569634\tbest: 0.7569634 (800)\ttotal: 15.1s\tremaining: 13.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7570497\tbest: 0.7574198 (847)\ttotal: 16.8s\tremaining: 11.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7574197598\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 847\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 848 iterations.\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.7574197598379406 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.7574197598379406 in 0:00:17.814391\n",
            "Optimization Progress:  10%|▉         | 10/101 [03:14<29:24, 19.39s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5619450\tbest: 0.5619450 (0)\ttotal: 16.8ms\tremaining: 25.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7439807\tbest: 0.7440190 (99)\ttotal: 1.49s\tremaining: 20.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7498635\tbest: 0.7498854 (199)\ttotal: 2.98s\tremaining: 19.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7520053\tbest: 0.7520508 (292)\ttotal: 5.48s\tremaining: 21.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7532914\tbest: 0.7533049 (398)\ttotal: 7.44s\tremaining: 20.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7546664\tbest: 0.7546803 (488)\ttotal: 8.91s\tremaining: 17.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7558670\tbest: 0.7558670 (600)\ttotal: 10.4s\tremaining: 15.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7566426\tbest: 0.7566764 (684)\ttotal: 11.8s\tremaining: 13.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7576455\tbest: 0.7577082 (783)\ttotal: 13.3s\tremaining: 11.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7578436\tbest: 0.7578641 (899)\ttotal: 14.8s\tremaining: 9.82s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7579815\tbest: 0.7581810 (953)\ttotal: 16.2s\tremaining: 8.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7583861\tbest: 0.7585448 (1077)\ttotal: 19.2s\tremaining: 6.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7592722\tbest: 0.7592722 (1200)\ttotal: 20.7s\tremaining: 5.15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7598058\tbest: 0.7598229 (1297)\ttotal: 22.2s\tremaining: 3.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7597789\tbest: 0.7600977 (1369)\ttotal: 23.7s\tremaining: 1.67s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7600976953\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1369\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1370 iterations.\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.760097675038948 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.014413007523517646, 'min_data_in_leaf': 19}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.014413007523517646, 'min_data_in_leaf': 19} scored 0.760097675038948 in 0:00:25.034746\n",
            "Optimization Progress:  11%|█         | 11/101 [03:39<31:40, 21.12s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5619450\tbest: 0.5619450 (0)\ttotal: 18.2ms\tremaining: 27.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7431112\tbest: 0.7431112 (100)\ttotal: 1.58s\tremaining: 21.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7474886\tbest: 0.7474886 (200)\ttotal: 3.13s\tremaining: 20.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7499285\tbest: 0.7499285 (300)\ttotal: 6.33s\tremaining: 25.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7523225\tbest: 0.7523225 (400)\ttotal: 9.07s\tremaining: 24.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7536947\tbest: 0.7536947 (500)\ttotal: 11.2s\tremaining: 22.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7549283\tbest: 0.7549283 (600)\ttotal: 13.6s\tremaining: 20.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7561830\tbest: 0.7561830 (700)\ttotal: 15.2s\tremaining: 17.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7572315\tbest: 0.7572375 (799)\ttotal: 16.7s\tremaining: 14.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7583659\tbest: 0.7583659 (900)\ttotal: 19.9s\tremaining: 13.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7585922\tbest: 0.7586080 (971)\ttotal: 21.5s\tremaining: 10.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7592062\tbest: 0.7592400 (1098)\ttotal: 23s\tremaining: 8.35s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7594085\tbest: 0.7595920 (1139)\ttotal: 24.6s\tremaining: 6.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7599740\tbest: 0.7599743 (1298)\ttotal: 26.1s\tremaining: 4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7606706\tbest: 0.7606720 (1399)\ttotal: 27.7s\tremaining: 1.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1499:\ttest: 0.7609688\tbest: 0.7609863 (1455)\ttotal: 29.3s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7609863136\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1455\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1456 iterations.\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.7609863135760359 and parameters: {'max_depth': 4, 'l2_leaf_reg': 8.139689956202588, 'min_data_in_leaf': 16}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 8.139689956202588, 'min_data_in_leaf': 16} scored 0.7609863135760359 in 0:00:29.624480\n",
            "Optimization Progress:  12%|█▏        | 12/101 [04:09<35:10, 23.71s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5619450\tbest: 0.5619450 (0)\ttotal: 28.3ms\tremaining: 42.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7434717\tbest: 0.7434717 (100)\ttotal: 2.86s\tremaining: 39.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7480802\tbest: 0.7480802 (200)\ttotal: 4.39s\tremaining: 28.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7512572\tbest: 0.7512572 (300)\ttotal: 5.91s\tremaining: 23.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7529927\tbest: 0.7529927 (400)\ttotal: 7.36s\tremaining: 20.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7536714\tbest: 0.7536747 (499)\ttotal: 8.83s\tremaining: 17.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7551451\tbest: 0.7551451 (600)\ttotal: 10.3s\tremaining: 15.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7565106\tbest: 0.7565238 (697)\ttotal: 11.9s\tremaining: 13.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7571002\tbest: 0.7571122 (799)\ttotal: 14.5s\tremaining: 12.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7579893\tbest: 0.7579893 (900)\ttotal: 16.2s\tremaining: 10.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7583057\tbest: 0.7583057 (1000)\ttotal: 17.7s\tremaining: 8.81s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7586634\tbest: 0.7586672 (1099)\ttotal: 19.2s\tremaining: 6.95s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7591025\tbest: 0.7591238 (1199)\ttotal: 20.6s\tremaining: 5.13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7599644\tbest: 0.7599644 (1300)\ttotal: 22.1s\tremaining: 3.38s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7602490\tbest: 0.7602903 (1371)\ttotal: 23.6s\tremaining: 1.67s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1499:\ttest: 0.7609025\tbest: 0.7609025 (1499)\ttotal: 25.2s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7609024786\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1499\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.7609025191436023 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.18142164231844107, 'min_data_in_leaf': 7}. Best is trial 0 with value: 0.7614400075240672.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.18142164231844107, 'min_data_in_leaf': 7} scored 0.7609025191436023 in 0:00:25.656647\n",
            "Optimization Progress:  13%|█▎        | 13/101 [04:35<35:38, 24.31s/it, best_trial=0, best_value=0.761]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5816465\tbest: 0.5816465 (0)\ttotal: 39.3ms\tremaining: 58.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7474984\tbest: 0.7475202 (99)\ttotal: 3.02s\tremaining: 41.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7528563\tbest: 0.7528563 (200)\ttotal: 4.96s\tremaining: 32.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7557506\tbest: 0.7557506 (300)\ttotal: 6.88s\tremaining: 27.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7582330\tbest: 0.7582330 (400)\ttotal: 8.81s\tremaining: 24.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7599355\tbest: 0.7599578 (499)\ttotal: 10.7s\tremaining: 21.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7613307\tbest: 0.7613307 (600)\ttotal: 13.8s\tremaining: 20.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7621789\tbest: 0.7621789 (700)\ttotal: 16.1s\tremaining: 18.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7629654\tbest: 0.7630821 (762)\ttotal: 18s\tremaining: 15.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7644111\tbest: 0.7644352 (898)\ttotal: 20s\tremaining: 13.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7646396\tbest: 0.7648157 (991)\ttotal: 21.9s\tremaining: 10.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7651466\tbest: 0.7652079 (1092)\ttotal: 23.9s\tremaining: 8.65s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7652353\tbest: 0.7653031 (1184)\ttotal: 27.3s\tremaining: 6.79s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7654831\tbest: 0.7655391 (1265)\ttotal: 29.2s\tremaining: 4.47s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7655390633\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1265\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1266 iterations.\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.7655390633266187 and parameters: {'max_depth': 6, 'l2_leaf_reg': 8.26298378980132, 'min_data_in_leaf': 16}. Best is trial 13 with value: 0.7655390633266187.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 8.26298378980132, 'min_data_in_leaf': 16} scored 0.7655390633266187 in 0:00:30.918316\n",
            "Optimization Progress:  14%|█▍        | 14/101 [05:06<31:42, 21.87s/it, best_trial=13, best_value=0.766]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:06:30] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 6, 'l2_leaf_reg': 8.26298378980132, 'min_data_in_leaf': 16}\u001b[0m\n",
            " achieve 0.7655 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:06:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 8.26298378980132, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 6, 'min_data_in_leaf': 16, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5816465\tbest: 0.5816465 (0)\ttotal: 18ms\tremaining: 54s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7428354\tbest: 0.7428354 (100)\ttotal: 1.95s\tremaining: 55.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7490053\tbest: 0.7490053 (200)\ttotal: 3.89s\tremaining: 54.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7516410\tbest: 0.7516410 (300)\ttotal: 5.8s\tremaining: 52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7538676\tbest: 0.7538676 (400)\ttotal: 9.16s\tremaining: 59.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7559836\tbest: 0.7559836 (500)\ttotal: 11.1s\tremaining: 55.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7572162\tbest: 0.7572162 (600)\ttotal: 13s\tremaining: 51.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7587254\tbest: 0.7587283 (698)\ttotal: 14.9s\tremaining: 48.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7597326\tbest: 0.7597392 (798)\ttotal: 16.9s\tremaining: 46.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7608658\tbest: 0.7608658 (900)\ttotal: 19.1s\tremaining: 44.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7616614\tbest: 0.7617414 (985)\ttotal: 22.2s\tremaining: 44.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7625788\tbest: 0.7626475 (1097)\ttotal: 24.1s\tremaining: 41.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7630804\tbest: 0.7632184 (1189)\ttotal: 26s\tremaining: 39s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7635544\tbest: 0.7635856 (1296)\ttotal: 28s\tremaining: 36.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7639811\tbest: 0.7640351 (1395)\ttotal: 29.9s\tremaining: 34.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.7645457\tbest: 0.7645692 (1492)\ttotal: 33s\tremaining: 33s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.7648668\tbest: 0.7649483 (1593)\ttotal: 35.3s\tremaining: 30.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.7650038\tbest: 0.7652025 (1648)\ttotal: 37.2s\tremaining: 28.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.7651506\tbest: 0.7652338 (1787)\ttotal: 39.1s\tremaining: 26s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.7653600\tbest: 0.7654574 (1884)\ttotal: 41.1s\tremaining: 23.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.7652818\tbest: 0.7654967 (1942)\ttotal: 43s\tremaining: 21.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.7657055\tbest: 0.7657384 (2097)\ttotal: 46.5s\tremaining: 19.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2200:\ttest: 0.7660542\tbest: 0.7660713 (2185)\ttotal: 48.5s\tremaining: 17.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2300:\ttest: 0.7662310\tbest: 0.7662736 (2237)\ttotal: 50.5s\tremaining: 15.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2400:\ttest: 0.7664058\tbest: 0.7664058 (2400)\ttotal: 52.5s\tremaining: 13.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2500:\ttest: 0.7666862\tbest: 0.7667205 (2495)\ttotal: 54.4s\tremaining: 10.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2600:\ttest: 0.7668852\tbest: 0.7669886 (2592)\ttotal: 56.8s\tremaining: 8.71s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2700:\ttest: 0.7668653\tbest: 0.7669940 (2612)\ttotal: 59.8s\tremaining: 6.62s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.766993973\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2612\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2613 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5750286\tbest: 0.5750286 (0)\ttotal: 17.8ms\tremaining: 53.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7233524\tbest: 0.7233524 (100)\ttotal: 1.95s\tremaining: 55.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7286993\tbest: 0.7288127 (197)\ttotal: 3.87s\tremaining: 53.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7316271\tbest: 0.7316271 (300)\ttotal: 5.75s\tremaining: 51.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7327330\tbest: 0.7327330 (400)\ttotal: 7.66s\tremaining: 49.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7340351\tbest: 0.7340704 (492)\ttotal: 11s\tremaining: 55s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7351719\tbest: 0.7352258 (596)\ttotal: 12.9s\tremaining: 51.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7362069\tbest: 0.7362069 (700)\ttotal: 14.9s\tremaining: 48.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7371657\tbest: 0.7371657 (800)\ttotal: 16.8s\tremaining: 46.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7378645\tbest: 0.7378645 (900)\ttotal: 18.7s\tremaining: 43.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7382601\tbest: 0.7382856 (995)\ttotal: 20.6s\tremaining: 41.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7387514\tbest: 0.7387533 (1097)\ttotal: 24s\tremaining: 41.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7393562\tbest: 0.7393945 (1181)\ttotal: 25.9s\tremaining: 38.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7396111\tbest: 0.7396170 (1296)\ttotal: 27.8s\tremaining: 36.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7400768\tbest: 0.7400979 (1399)\ttotal: 29.8s\tremaining: 34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.7401903\tbest: 0.7402603 (1463)\ttotal: 31.7s\tremaining: 31.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.7403240\tbest: 0.7403849 (1595)\ttotal: 33.9s\tremaining: 29.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.7407112\tbest: 0.7407612 (1692)\ttotal: 37s\tremaining: 28.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.7411757\tbest: 0.7412694 (1787)\ttotal: 39s\tremaining: 25.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.7414164\tbest: 0.7415495 (1874)\ttotal: 40.9s\tremaining: 23.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7415495322\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1874\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1875 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5826177\tbest: 0.5826177 (0)\ttotal: 18.6ms\tremaining: 55.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7292884\tbest: 0.7292884 (100)\ttotal: 1.93s\tremaining: 55.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7336950\tbest: 0.7336950 (200)\ttotal: 4.65s\tremaining: 1m 4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7351847\tbest: 0.7352315 (297)\ttotal: 7.26s\tremaining: 1m 5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7363751\tbest: 0.7363751 (400)\ttotal: 9.18s\tremaining: 59.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7376384\tbest: 0.7376916 (489)\ttotal: 11.1s\tremaining: 55.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7384664\tbest: 0.7385529 (592)\ttotal: 13s\tremaining: 51.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7398663\tbest: 0.7399131 (687)\ttotal: 14.9s\tremaining: 48.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7409461\tbest: 0.7409461 (800)\ttotal: 18.2s\tremaining: 50.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7413990\tbest: 0.7414081 (898)\ttotal: 20.2s\tremaining: 47s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7420402\tbest: 0.7420994 (997)\ttotal: 22.1s\tremaining: 44.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7419942\tbest: 0.7422136 (1090)\ttotal: 24s\tremaining: 41.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7426543\tbest: 0.7426543 (1200)\ttotal: 25.9s\tremaining: 38.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7434041\tbest: 0.7434294 (1285)\ttotal: 27.9s\tremaining: 36.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7438409\tbest: 0.7438757 (1397)\ttotal: 31.3s\tremaining: 35.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.7440121\tbest: 0.7441394 (1482)\ttotal: 33.2s\tremaining: 33.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.7447527\tbest: 0.7448234 (1596)\ttotal: 35.2s\tremaining: 30.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.7452574\tbest: 0.7454569 (1680)\ttotal: 37.1s\tremaining: 28.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.7457923\tbest: 0.7457936 (1797)\ttotal: 39s\tremaining: 26s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.7463167\tbest: 0.7463292 (1899)\ttotal: 41.5s\tremaining: 24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.7465116\tbest: 0.7466398 (1942)\ttotal: 44.4s\tremaining: 22.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.7466903\tbest: 0.7467647 (2080)\ttotal: 46.3s\tremaining: 19.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2200:\ttest: 0.7471613\tbest: 0.7472317 (2191)\ttotal: 48.3s\tremaining: 17.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2300:\ttest: 0.7472199\tbest: 0.7473000 (2244)\ttotal: 50.2s\tremaining: 15.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2400:\ttest: 0.7478542\tbest: 0.7478623 (2370)\ttotal: 52.1s\tremaining: 13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2500:\ttest: 0.7482870\tbest: 0.7483774 (2491)\ttotal: 55.4s\tremaining: 11.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2600:\ttest: 0.7485088\tbest: 0.7486171 (2537)\ttotal: 57.5s\tremaining: 8.82s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7486171238\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2537\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2538 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5774534\tbest: 0.5774534 (0)\ttotal: 21.4ms\tremaining: 1m 4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7314625\tbest: 0.7314625 (100)\ttotal: 1.93s\tremaining: 55.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7371747\tbest: 0.7371747 (200)\ttotal: 3.82s\tremaining: 53.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7399535\tbest: 0.7399535 (300)\ttotal: 5.77s\tremaining: 51.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7416205\tbest: 0.7417182 (398)\ttotal: 8.52s\tremaining: 55.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7430389\tbest: 0.7430671 (499)\ttotal: 11.1s\tremaining: 55.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7440595\tbest: 0.7440658 (596)\ttotal: 13s\tremaining: 52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7449303\tbest: 0.7449303 (700)\ttotal: 14.9s\tremaining: 49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7459918\tbest: 0.7460169 (797)\ttotal: 16.9s\tremaining: 46.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7470115\tbest: 0.7470366 (895)\ttotal: 18.8s\tremaining: 43.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7475150\tbest: 0.7475157 (999)\ttotal: 22.2s\tremaining: 44.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7482330\tbest: 0.7482505 (1094)\ttotal: 24.2s\tremaining: 41.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7484797\tbest: 0.7485385 (1183)\ttotal: 26.1s\tremaining: 39s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7491812\tbest: 0.7491812 (1300)\ttotal: 28s\tremaining: 36.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7496226\tbest: 0.7496355 (1398)\ttotal: 29.9s\tremaining: 34.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.7502120\tbest: 0.7502407 (1499)\ttotal: 31.9s\tremaining: 31.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.7504839\tbest: 0.7505410 (1596)\ttotal: 35.3s\tremaining: 30.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1700:\ttest: 0.7507995\tbest: 0.7508848 (1681)\ttotal: 37.3s\tremaining: 28.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1800:\ttest: 0.7511526\tbest: 0.7511526 (1800)\ttotal: 39.2s\tremaining: 26.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1900:\ttest: 0.7512542\tbest: 0.7512542 (1900)\ttotal: 41.2s\tremaining: 23.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2000:\ttest: 0.7517070\tbest: 0.7517534 (1995)\ttotal: 43.1s\tremaining: 21.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2100:\ttest: 0.7518813\tbest: 0.7518813 (2100)\ttotal: 45.5s\tremaining: 19.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2200:\ttest: 0.7522909\tbest: 0.7523377 (2158)\ttotal: 48.5s\tremaining: 17.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:2300:\ttest: 0.7526306\tbest: 0.7527331 (2248)\ttotal: 50.4s\tremaining: 15.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7527330757\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2248\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2249 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5960564\tbest: 0.5960564 (0)\ttotal: 21ms\tremaining: 1m 3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7295330\tbest: 0.7295330 (100)\ttotal: 1.94s\tremaining: 55.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7339060\tbest: 0.7339172 (194)\ttotal: 3.84s\tremaining: 53.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7365615\tbest: 0.7365615 (300)\ttotal: 5.86s\tremaining: 52.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7383376\tbest: 0.7383737 (399)\ttotal: 9.11s\tremaining: 59s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7400953\tbest: 0.7400953 (500)\ttotal: 11s\tremaining: 55.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7413213\tbest: 0.7413213 (600)\ttotal: 13s\tremaining: 51.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7415584\tbest: 0.7417514 (650)\ttotal: 14.9s\tremaining: 48.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:800:\ttest: 0.7421817\tbest: 0.7421862 (796)\ttotal: 16.8s\tremaining: 46.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:900:\ttest: 0.7428734\tbest: 0.7428838 (899)\ttotal: 19.5s\tremaining: 45.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.7429702\tbest: 0.7430571 (991)\ttotal: 22.1s\tremaining: 44.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1100:\ttest: 0.7434185\tbest: 0.7435515 (1080)\ttotal: 24s\tremaining: 41.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1200:\ttest: 0.7437278\tbest: 0.7437852 (1198)\ttotal: 25.9s\tremaining: 38.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1300:\ttest: 0.7443666\tbest: 0.7443666 (1300)\ttotal: 27.8s\tremaining: 36.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1400:\ttest: 0.7446953\tbest: 0.7448260 (1364)\ttotal: 29.8s\tremaining: 34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1500:\ttest: 0.7450686\tbest: 0.7450963 (1498)\ttotal: 33.2s\tremaining: 33.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:1600:\ttest: 0.7452561\tbest: 0.7453938 (1524)\ttotal: 35.1s\tremaining: 30.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7453938323\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1524\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1525 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7509427414428776\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7509427414428776\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:39] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:39] Time left 2352.52 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 2352.52 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:39] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:39] Blending: optimization starts with equal weights. Score = \u001b[1m0.7611602\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights. Score = \u001b[1m0.7611602\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:41] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7651587\u001b[0m, weights = \u001b[1m[0.         0.22918144 0.56064713 0.083904   0.12626745]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7651587\u001b[0m, weights = \u001b[1m[0.         0.22918144 0.56064713 0.083904   0.12626745]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:42] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7655723\u001b[0m, weights = \u001b[1m[0.07306641 0.23556367 0.556696   0.         0.13467398]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7655723\u001b[0m, weights = \u001b[1m[0.07306641 0.23556367 0.556696   0.         0.13467398]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:43] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7656289\u001b[0m, weights = \u001b[1m[0.09929205 0.2502909  0.5327831  0.         0.11763398]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7656289\u001b[0m, weights = \u001b[1m[0.09929205 0.2502909  0.5327831  0.         0.11763398]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:44] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7656312\u001b[0m, weights = \u001b[1m[0.1011992  0.2555716  0.5268953  0.         0.11633399]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7656312\u001b[0m, weights = \u001b[1m[0.1011992  0.2555716  0.5268953  0.         0.11633399]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:46] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.7656320\u001b[0m, weights = \u001b[1m[0.10233946 0.25619945 0.52619106 0.         0.11527   ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.7656320\u001b[0m, weights = \u001b[1m[0.10233946 0.25619945 0.52619106 0.         0.11527   ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:46] Blending: best score = \u001b[1m0.7656320\u001b[0m, best weights = \u001b[1m[0.10233946 0.25619945 0.52619106 0.         0.11527   ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: best score = \u001b[1m0.7656320\u001b[0m, best weights = \u001b[1m[0.10233946 0.25619945 0.52619106 0.         0.11527   ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:46] \u001b[1mAutoml preset training completed in 1253.72 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 1253.72 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:10:46] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.10234 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.25620 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
            "\t 0.52619 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
            "\t 0.11527 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.10234 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.25620 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
            "\t 0.52619 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
            "\t 0.11527 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка модели...\n",
            "\n",
            "==================================================\n",
            "РЕЗУЛЬТАТЫ AUTOML ДЛЯ БИНАРНОЙ КЛАССИФИКАЦИИ\n",
            "==================================================\n",
            "ROC-AUC на тестовых данных: 0.7561\n",
            "MAE на тестовых данных: 0.1401\n",
            "ROC-AUC на тренировочных данных: 0.9170\n",
            "\n",
            "Не удалось получить важность признаков: 'importance'\n",
            "\n",
            "AutoML обучение завершено успешно!\n",
            "Отчет сохранен в файл: AutoML_classification_report.html\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}