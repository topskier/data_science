{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b625997",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "# Python 3.12\n",
    "%env CLEARML_API_ACCESS_KEY=17EH8MKOUXFTCCY4ZNGB7KOEIGXU59\n",
    "%env CLEARML_API_SECRET_KEY=I3XdWFGE-rw1-16wvP-F1uV6Uq143N7igmA6hAOetL8a8oj-4Xi32kYHC78lhjSCRzc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498d95c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_community.llms import GigaChat\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from clearml import Task, Logger, StorageManager, Dataset\n",
    "import os\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8607ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayEvaluation(BaseModel):\n",
    "    H1: int = Field(description=\"Балл по критерию K1\", ge=0, le=1)\n",
    "    H1_explanation: str = Field(description=\"Обоснование оценки по критерию K1\")\n",
    "    H2: int = Field(description=\"Балл по критерию K2\", ge=0, le=3)\n",
    "    H2_explanation: str = Field(description=\"Обоснование оценки по критерию K2\")\n",
    "    H3: int = Field(description=\"Балл по критерию K3\", ge=0, le=2)\n",
    "    H3_explanation: str = Field(description=\"Обоснование оценки по критерию K3\")\n",
    "    H4: int = Field(description=\"Балл по критерию K4\", ge=0, le=1)\n",
    "    H4_explanation: str = Field(description=\"Обоснование оценки по критерию K4\")\n",
    "\n",
    "def setup_llm():\n",
    "    \"\"\"Настройка GigaChat\"\"\"\n",
    "    llm = GigaChat(\n",
    "        credentials=\"YzJiZGZmM2MtYjdlMy00OGE5LWE5YmItNTg3MDZiYjJiZTE3OmY2OTc2NmJlLWU2NmQtNDBhYS1iNjVhLWFkZDQxNmNkYmFiMA==\", \n",
    "        verify_ssl_certs=False,\n",
    "        model='GigaChat-2',\n",
    "        temperature=0.1,\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969a4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompts(parser):\n",
    "    \"\"\"Создание промптов для разных типов сочинений\"\"\"\n",
    "    \n",
    "    # Промпт для типа 1 (13.1 - лингвистическое сочинение)\n",
    "    prompt_type1 = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Ты - эксперт по проверке сочинений ОГЭ по русскому языку. \n",
    "Оцени сочинение по критериям К1-К4 для задания типа 13.1 (лингвистическое сочинение).\n",
    "\n",
    "КРИТЕРИИ ОЦЕНКИ для типа 1:\n",
    "К1 (0-1 балл): Наличие обоснованного ответа на лингвистический вопрос. Рассуждение на теоретическом уровне, отсутствие фактических ошибок.\n",
    "К2 (0-3 балла): Приведение двух примеров-иллюстраций из опорного текста, соответствующих теме.\n",
    "К3 (0-2 балла): Логичность речи - смысловая цельность, связность, последовательность изложения. 0 ошибок = 2 балла, 1 ошибка = 1 балл, >1 ошибки = 0 баллов.\n",
    "К4 (0-1 балл): Композиционная стройность - трехчастная композиция, завершенность. ≤1 ошибка = 1 балл, иначе 0.\n",
    "\n",
    "Текст задания: {task_text}\n",
    "Тип сочинения: 1 (13.1)\n",
    "\n",
    "Верни ответ строго в указанном JSON-формате.\"\"\"),\n",
    "        (\"human\", \"Текст сочинения: {essay_text}\\n\\n{format_instructions}\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    # Промпт для типа 2 (13.2 - литературно-тематическое сочинение)\n",
    "    prompt_type2 = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Ты - эксперт по проверке сочинений ОГЭ по русскому языку. \n",
    "Оцени сочинение по критериям К1-К4 для задания типа 13.2 (литературно-тематическое сочинение).\n",
    "\n",
    "КРИТЕРИИ ОЦЕНКИ для типа 2:\n",
    "К1 (0-1 балл): Понимание смысла фрагмента текста - верное объяснение содержания фрагмента.\n",
    "К2 (0-3 балла): Приведение двух примеров-иллюстраций из опорного текста, иллюстрирующих понимание фрагмента.\n",
    "К3 (0-2 балла): Логичность речи - смысловая цельность, связность, последовательность изложения. 0 ошибок = 2 балла, 1 ошибка = 1 балл, >1 ошибки = 0 баллов.\n",
    "К4 (0-1 балл): Композиционная стройность - трехчастная композиция, завершенность. ≤1 ошибка = 1 балл, иначе 0.\n",
    "\n",
    "Текст задания: {task_text}\n",
    "Тип сочинения: 2 (13.2)\n",
    "\n",
    "Верни ответ строго в указанном JSON-формате.\"\"\"),\n",
    "        (\"human\", \"Текст сочинения: {essay_text}\\n\\n{format_instructions}\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    # Промпт для типа 3 (13.3 - морально-нравственное сочинение)\n",
    "    prompt_type3 = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Ты - эксперт по проверке сочинений ОГЭ по русскому языку. \n",
    "Оцени сочинение по критериям К1-К4 для задания типа 13.3 (морально-нравственное сочинение).\n",
    "\n",
    "КРИТЕРИИ ОЦЕНКИ для типа 3:\n",
    "К1 (0-1 балл): Наличие обоснованного ответа на поставленный вопрос.\n",
    "К2 (0-3 балла): Приведение одного примера из опорного текста и одного примера из личного опыта/литературы.\n",
    "К3 (0-2 балла): Логичность речи - смысловая цельность, связность, последовательность изложения. 0 ошибок = 2 балла, 1 ошибка = 1 балл, >1 ошибки = 0 баллов.\n",
    "К4 (0-1 балл): Композиционная стройность - трехчастная композиция, завершенность. ≤1 ошибка = 1 балл, иначе 0.\n",
    "\n",
    "Текст задания: {task_text}\n",
    "Тип сочинения: 3 (13.3)\n",
    "\n",
    "Верни ответ строго в указанном JSON-формате.\"\"\"),\n",
    "        (\"human\", \"Текст сочинения: {essay_text}\\n\\n{format_instructions}\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    return prompt_type1, prompt_type2, prompt_type3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3984207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_essays(test_csv_path, output_csv_path=\"submission.csv\"):\n",
    "    \"\"\"Основная функция для оценки сочинений\"\"\"\n",
    "    \n",
    "    # Инициализация компонентов\n",
    "    llm = setup_llm()\n",
    "    parser = PydanticOutputParser(pydantic_object=EssayEvaluation)\n",
    "    prompt_type1, prompt_type2, prompt_type3 = create_prompts(parser)\n",
    "    \n",
    "    # Создаем цепочки для каждого типа сочинения\n",
    "    chain1 = LLMChain(llm=llm, prompt=prompt_type1, output_parser=parser)\n",
    "    chain2 = LLMChain(llm=llm, prompt=prompt_type2, output_parser=parser)\n",
    "    chain3 = LLMChain(llm=llm, prompt=prompt_type3, output_parser=parser)\n",
    "    \n",
    "    # Загрузка тестовых данных\n",
    "    test_data = pd.read_csv(test_csv_path)\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Начинаем обработку {len(test_data)} сочинений...\")\n",
    "    \n",
    "    for idx, row in test_data.iterrows():\n",
    "        try:\n",
    "            essay_type = row[\"essay_type\"]\n",
    "            essay_text = row[\"essay_text\"]\n",
    "            task_text = row[\"task_text\"]\n",
    "            \n",
    "            # Получаем предсказание в зависимости от типа сочинения\n",
    "            if essay_type == 1:\n",
    "                result = chain1.invoke({\"essay_text\": essay_text, \"task_text\": task_text})\n",
    "            elif essay_type == 2:\n",
    "                result = chain2.invoke({\"essay_text\": essay_text, \"task_text\": task_text})\n",
    "            elif essay_type == 3:\n",
    "                result = chain3.invoke({\"essay_text\": essay_text, \"task_text\": task_text})\n",
    "            else:\n",
    "                print(f\"Неизвестный тип сочинения: {essay_type}\")\n",
    "                continue\n",
    "                \n",
    "            evaluation = result[\"text\"]\n",
    "            \n",
    "            results.append({\n",
    "                \"essay_id\": row[\"essay_id\"],\n",
    "                \"H1\": evaluation.H1,\n",
    "                \"H1_explanation\": evaluation.H1_explanation,\n",
    "                \"H2\": evaluation.H2,\n",
    "                \"H2_explanation\": evaluation.H2_explanation,\n",
    "                \"H3\": evaluation.H3,\n",
    "                \"H3_explanation\": evaluation.H3_explanation,\n",
    "                \"H4\": evaluation.H4,\n",
    "                \"H4_explanation\": evaluation.H4_explanation\n",
    "            })\n",
    "            \n",
    "            print(f\"Обработано сочинение {idx + 1}/{len(test_data)} (ID: {row['essay_id']})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке essay_id {row['essay_id']}: {str(e)}\")\n",
    "            # Добавляем запись с нулевыми значениями в случае ошибки\n",
    "            results.append({\n",
    "                \"essay_id\": row[\"essay_id\"],\n",
    "                \"H1\": 0,\n",
    "                \"H1_explanation\": f\"Ошибка обработки: {str(e)}\",\n",
    "                \"H2\": 0,\n",
    "                \"H2_explanation\": f\"Ошибка обработки: {str(e)}\",\n",
    "                \"H3\": 0,\n",
    "                \"H3_explanation\": f\"Ошибка обработки: {str(e)}\",\n",
    "                \"H4\": 0,\n",
    "                \"H4_explanation\": f\"Ошибка обработки: {str(e)}\"\n",
    "            })\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Результаты сохранены в {output_csv_path}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff8155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обработку 56 сочинений...\n",
      "Ошибка при обработке essay_id 1: 'task_text'\n",
      "Ошибка при обработке essay_id 2: 'task_text'\n",
      "Ошибка при обработке essay_id 6: 'task_text'\n",
      "Ошибка при обработке essay_id 7: 'task_text'\n",
      "Ошибка при обработке essay_id 8: 'task_text'\n",
      "Ошибка при обработке essay_id 9: 'task_text'\n",
      "Ошибка при обработке essay_id 10: 'task_text'\n",
      "Ошибка при обработке essay_id 11: 'task_text'\n",
      "Ошибка при обработке essay_id 12: 'task_text'\n",
      "Ошибка при обработке essay_id 13: 'task_text'\n",
      "Ошибка при обработке essay_id 14: 'task_text'\n",
      "Ошибка при обработке essay_id 15: 'task_text'\n",
      "Ошибка при обработке essay_id 3: 'task_text'\n",
      "Ошибка при обработке essay_id 4: 'task_text'\n",
      "Ошибка при обработке essay_id 5: 'task_text'\n",
      "Ошибка при обработке essay_id 41: 'task_text'\n",
      "Ошибка при обработке essay_id 42: 'task_text'\n",
      "Ошибка при обработке essay_id 43: 'task_text'\n",
      "Ошибка при обработке essay_id 53: 'task_text'\n",
      "Ошибка при обработке essay_id 55: 'task_text'\n",
      "Ошибка при обработке essay_id 56: 'task_text'\n",
      "Ошибка при обработке essay_id 44: 'task_text'\n",
      "Ошибка при обработке essay_id 46: 'task_text'\n",
      "Ошибка при обработке essay_id 16: 'task_text'\n",
      "Ошибка при обработке essay_id 17: 'task_text'\n",
      "Ошибка при обработке essay_id 18: 'task_text'\n",
      "Ошибка при обработке essay_id 19: 'task_text'\n",
      "Ошибка при обработке essay_id 20: 'task_text'\n",
      "Ошибка при обработке essay_id 21: 'task_text'\n",
      "Ошибка при обработке essay_id 29: 'task_text'\n",
      "Ошибка при обработке essay_id 30: 'task_text'\n",
      "Ошибка при обработке essay_id 31: 'task_text'\n",
      "Ошибка при обработке essay_id 32: 'task_text'\n",
      "Ошибка при обработке essay_id 33: 'task_text'\n",
      "Ошибка при обработке essay_id 34: 'task_text'\n",
      "Ошибка при обработке essay_id 35: 'task_text'\n",
      "Ошибка при обработке essay_id 36: 'task_text'\n",
      "Ошибка при обработке essay_id 37: 'task_text'\n",
      "Ошибка при обработке essay_id 38: 'task_text'\n",
      "Ошибка при обработке essay_id 39: 'task_text'\n",
      "Ошибка при обработке essay_id 22: 'task_text'\n",
      "Ошибка при обработке essay_id 23: 'task_text'\n",
      "Ошибка при обработке essay_id 24: 'task_text'\n",
      "Ошибка при обработке essay_id 25: 'task_text'\n",
      "Ошибка при обработке essay_id 26: 'task_text'\n",
      "Ошибка при обработке essay_id 27: 'task_text'\n",
      "Ошибка при обработке essay_id 28: 'task_text'\n",
      "Ошибка при обработке essay_id 40: 'task_text'\n",
      "Ошибка при обработке essay_id 47: 'task_text'\n",
      "Ошибка при обработке essay_id 48: 'task_text'\n",
      "Ошибка при обработке essay_id 54: 'task_text'\n",
      "Ошибка при обработке essay_id 45: 'task_text'\n",
      "Ошибка при обработке essay_id 49: 'task_text'\n",
      "Ошибка при обработке essay_id 50: 'task_text'\n",
      "Ошибка при обработке essay_id 51: 'task_text'\n",
      "Ошибка при обработке essay_id 52: 'task_text'\n",
      "Результаты сохранены в submission.csv\n",
      "\n",
      "==================================================\n",
      "СТАТИСТИКА ОЦЕНОК:\n",
      "==================================================\n",
      "Средний балл H1: 0.00\n",
      "Средний балл H2: 0.00\n",
      "Средний балл H3: 0.00\n",
      "Средний балл H4: 0.00\n",
      "\n",
      "Общее количество обработанных сочинений: 56\n",
      "Сочинений с ошибками обработки: 56\n",
      "\n",
      "==================================================\n",
      "ПЕРВЫЕ 3 РЕЗУЛЬТАТА:\n",
      "==================================================\n",
      "\n",
      "Сочинение ID: 1\n",
      "  H1: 0 - Ошибка обработки: 'task_text'...\n",
      "  H2: 0 - Ошибка обработки: 'task_text'...\n",
      "\n",
      "Сочинение ID: 2\n",
      "  H1: 0 - Ошибка обработки: 'task_text'...\n",
      "  H2: 0 - Ошибка обработки: 'task_text'...\n",
      "\n",
      "Сочинение ID: 6\n",
      "  H1: 0 - Ошибка обработки: 'task_text'...\n",
      "  H2: 0 - Ошибка обработки: 'task_text'...\n",
      "\n",
      "Обработка завершена успешно!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_12860\\1063364025.py:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain1 = LLMChain(llm=llm, prompt=prompt_type1, output_parser=parser)\n"
     ]
    }
   ],
   "source": [
    "def analyze_results(results_df):\n",
    "    \"\"\"Анализ и вывод статистики результатов\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"СТАТИСТИКА ОЦЕНОК:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Средний балл H1: {results_df['H1'].mean():.2f}\")\n",
    "    print(f\"Средний балл H2: {results_df['H2'].mean():.2f}\")\n",
    "    print(f\"Средний балл H3: {results_df['H3'].mean():.2f}\")\n",
    "    print(f\"Средний балл H4: {results_df['H4'].mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\nОбщее количество обработанных сочинений: {len(results_df)}\")\n",
    "    print(f\"Сочинений с ошибками обработки: {len(results_df[results_df['H1_explanation'].str.startswith('Ошибка обработки')])}\")\n",
    "    \n",
    "    # Показываем первые несколько результатов\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ПЕРВЫЕ 3 РЕЗУЛЬТАТА:\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(min(3, len(results_df))):\n",
    "        print(f\"\\nСочинение ID: {results_df.iloc[i]['essay_id']}\")\n",
    "        print(f\"  H1: {results_df.iloc[i]['H1']} - {results_df.iloc[i]['H1_explanation'][:100]}...\")\n",
    "        print(f\"  H2: {results_df.iloc[i]['H2']} - {results_df.iloc[i]['H2_explanation'][:100]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Основной блок выполнения\n",
    "    test_csv_path = \"D:/maga_poly/ML_3_sem/ml_polytech_3_sem/project/essays.csv\"  # Укажите путь к вашему test.csv\n",
    "    \n",
    "    try:\n",
    "        # Оцениваем сочинения\n",
    "        results_df = evaluate_essays(test_csv_path)\n",
    "        \n",
    "        # Анализируем результаты\n",
    "        analyze_results(results_df)\n",
    "        \n",
    "        print(\"\\nОбработка завершена успешно!\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Ошибка: Файл {test_csv_path} не найден.\")\n",
    "        print(\"Убедитесь, что файл test.csv находится в правильной директории.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
