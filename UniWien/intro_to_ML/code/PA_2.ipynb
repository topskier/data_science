{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7847865",
   "metadata": {},
   "source": [
    "# Task 1 Kernelized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a9c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import itertools\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a95a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X_digits, y_digits = digits.data, digits.target\n",
    "\n",
    "# Split data\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(\n",
    "    X_digits, y_digits, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976c2e5",
   "metadata": {},
   "source": [
    "## Subtask 1 SVMs With Different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d60153",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "best_models = {}\n",
    "for kernel in kernels:\n",
    "    if kernel == 'linear':\n",
    "        param_grid = {'C': [0.1, 1, 10]}\n",
    "    elif kernel == 'poly':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'degree': [2, 3]\n",
    "        }\n",
    "    else:  # rbf and sigmoid\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "    \n",
    "    grid = GridSearchCV(SVC(kernel=kernel), param_grid, cv=5)\n",
    "    grid.fit(X_train_d, y_train_d)\n",
    "    best_models[kernel] = grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b6e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Subtask 1: SVM with Different Kernels\n",
      "Kernel: linear\n",
      "Best params: {'C': 0.1}\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.9796\n",
      "\n",
      "Kernel: poly\n",
      "Best params: {'C': 0.1, 'degree': 3, 'gamma': 'auto'}\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.9889\n",
      "\n",
      "Kernel: rbf\n",
      "Best params: {'C': 10, 'gamma': 'scale'}\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.9889\n",
      "\n",
      "Kernel: sigmoid\n",
      "Best params: {'C': 1, 'gamma': 'scale'}\n",
      "Train Accuracy: 0.9196, Test Accuracy: 0.9074\n",
      "\n",
      "Method of choosing the best parameters: GridSearchCV\n"
     ]
    }
   ],
   "source": [
    "# Report results\n",
    "print(\"Task 1 - Subtask 1: SVM with Different Kernels\")\n",
    "for kernel, model in best_models.items():\n",
    "    train_acc = accuracy_score(y_train_d, model.predict(X_train_d))\n",
    "    test_acc = accuracy_score(y_test_d, model.predict(X_test_d))\n",
    "    print(f\"Kernel: {kernel}\")\n",
    "    print(f\"Best params: {model.best_params_}\")\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\\n\")\n",
    "print('Method of choosing the best parameters: GridSearchCV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca562ef",
   "metadata": {},
   "source": [
    "## Subtask 2 Develop Your Own Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c45e2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Task 1 - Subtask 2: Custom Kernel\n",
      "Custom Kernel Train Accuracy: 1.0000\n",
      "Custom Kernel Test Accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "def custom_kernel(X, Y):\n",
    "    # composite kernel: linear + RBF\n",
    "    linear = np.dot(X, Y.T)\n",
    "    rbf = np.exp(-0.1 * np.linalg.norm(X[:, None] - Y[None, :], axis=2)**2)\n",
    "    return linear + rbf\n",
    "\n",
    "# Validate kernel properties (positive definiteness)\n",
    "def is_positive_definite(K):\n",
    "    try:\n",
    "        np.linalg.cholesky(K)\n",
    "        return True\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False\n",
    "\n",
    "# Train SVM with custom kernel\n",
    "custom_svm = SVC(kernel=custom_kernel)\n",
    "custom_svm.fit(X_train_d, y_train_d)\n",
    "custom_train_acc = accuracy_score(y_train_d, custom_svm.predict(X_train_d))\n",
    "custom_test_acc = accuracy_score(y_test_d, custom_svm.predict(X_test_d))\n",
    "print(is_positive_definite(custom_kernel))\n",
    "print(\"Task 1 - Subtask 2: Custom Kernel\")\n",
    "print(f\"Custom Kernel Train Accuracy: {custom_train_acc:.4f}\")\n",
    "print(f\"Custom Kernel Test Accuracy: {custom_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809def81",
   "metadata": {},
   "source": [
    "## Subtask 3  Classifier Evaluation I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee26ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Subtask 3: Confusion Matrices\n",
      "Standard SVM Confusion Matrix:\n",
      "[[53  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 52  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 60  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 65  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 43  0]\n",
      " [ 0  0  0  0  0  0  0  1  1 57]]\n",
      "\n",
      "Custom SVM Confusion Matrix:\n",
      "[[53  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 52  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 60  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 65  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  1]\n",
      " [ 0  0  0  0  0  1  0  0 42  0]\n",
      " [ 0  0  0  0  0  0  0  1  1 57]]\n"
     ]
    }
   ],
   "source": [
    "def custom_confusion_matrix(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    cm = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    for i, true_label in enumerate(labels):\n",
    "        for j, pred_label in enumerate(labels):\n",
    "            cm[i, j] = np.sum((y_true == true_label) & (y_pred == pred_label))\n",
    "    return cm\n",
    "\n",
    "# Evaluate best models from Subtask 1 and 2\n",
    "best_standard_model = max(best_models.values(), key=lambda x: x.best_score_)\n",
    "standard_pred = best_standard_model.predict(X_test_d)\n",
    "custom_pred = custom_svm.predict(X_test_d)\n",
    "\n",
    "cm_standard = custom_confusion_matrix(y_test_d, standard_pred)\n",
    "cm_custom = custom_confusion_matrix(y_test_d, custom_pred)\n",
    "\n",
    "print(\"Task 1 - Subtask 3: Confusion Matrices\")\n",
    "print(\"Standard SVM Confusion Matrix:\")\n",
    "print(cm_standard)\n",
    "print(\"\\nCustom SVM Confusion Matrix:\")\n",
    "print(cm_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6bace",
   "metadata": {},
   "source": [
    "# Task 2 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f3ecbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X_cancer, y_cancer = cancer.data, cancer.target\n",
    "feature_names = cancer.feature_names\n",
    "\n",
    "# Normalize and split data\n",
    "scaler = MinMaxScaler()\n",
    "X_cancer_scaled = scaler.fit_transform(X_cancer)\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_cancer_scaled, y_cancer, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb7aa0",
   "metadata": {},
   "source": [
    "## Subtask 1 Forward Greedy Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(X, y, feature_names, model):\n",
    "    n_features = X.shape[1]\n",
    "    selected = []\n",
    "    scores = []\n",
    "    for _ in range(n_features):\n",
    "        best_score = -1\n",
    "        best_feature = None\n",
    "        for feature in range(n_features):\n",
    "            if feature not in selected:\n",
    "                current_features = selected + [feature]\n",
    "                score = np.mean(cross_val_score(model, X[:, current_features], y, cv=10))\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "        selected.append(best_feature)\n",
    "        scores.append(best_score)\n",
    "    return [feature_names[i] for i in selected], scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b0222d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lsvc = LinearSVC(random_state=42)\n",
    "forward_order, forward_scores = forward_selection(X_train_c, y_train_c, feature_names, model_lsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27041cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 2 - Subtask 1: Forward Selection\n",
      "Step 1: mean concave points - Score: 0.9071\n",
      "Step 2: worst texture - Score: 0.9372\n",
      "Step 3: worst radius - Score: 0.9648\n",
      "Step 4: worst concavity - Score: 0.9697\n",
      "Step 5: texture error - Score: 0.9748\n",
      "Step 6: mean concavity - Score: 0.9748\n",
      "Step 7: fractal dimension error - Score: 0.9749\n",
      "Step 8: mean texture - Score: 0.9749\n",
      "Step 9: mean smoothness - Score: 0.9749\n",
      "Step 10: mean compactness - Score: 0.9749\n",
      "Step 11: mean radius - Score: 0.9749\n",
      "Step 12: radius error - Score: 0.9749\n",
      "Step 13: mean symmetry - Score: 0.9749\n",
      "Step 14: mean perimeter - Score: 0.9749\n",
      "Step 15: worst smoothness - Score: 0.9749\n",
      "Step 16: worst concave points - Score: 0.9799\n",
      "Step 17: mean area - Score: 0.9799\n",
      "Step 18: mean fractal dimension - Score: 0.9799\n",
      "Step 19: worst symmetry - Score: 0.9799\n",
      "Step 20: area error - Score: 0.9799\n",
      "Step 21: compactness error - Score: 0.9799\n",
      "Step 22: smoothness error - Score: 0.9799\n",
      "Step 23: concave points error - Score: 0.9799\n",
      "Step 24: worst area - Score: 0.9799\n",
      "Step 25: symmetry error - Score: 0.9799\n",
      "Step 26: perimeter error - Score: 0.9774\n",
      "Step 27: concavity error - Score: 0.9749\n",
      "Step 28: worst perimeter - Score: 0.9749\n",
      "Step 29: worst compactness - Score: 0.9749\n",
      "Step 30: worst fractal dimension - Score: 0.9723\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTask 2 - Subtask 1: Forward Selection\")\n",
    "for i, (feature, score) in enumerate(zip(forward_order, forward_scores)):\n",
    "    print(f\"Step {i+1}: {feature} - Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abda4d3",
   "metadata": {},
   "source": [
    "## Subtask 2 Backward Greedy Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd9e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selection(X, y, feature_names, model):\n",
    "    n_features = X.shape[1]\n",
    "    selected = list(range(n_features))\n",
    "    scores = [np.mean(cross_val_score(model, X, y, cv=10))]\n",
    "    for _ in range(n_features-1):\n",
    "        worst_score = 1\n",
    "        worst_feature = None\n",
    "        for feature in selected:\n",
    "            current_features = [f for f in selected if f != feature]\n",
    "            score = np.mean(cross_val_score(model, X[:, current_features], y, cv=10))\n",
    "            if score < worst_score:\n",
    "                worst_score = score\n",
    "                worst_feature = feature\n",
    "        selected.remove(worst_feature)\n",
    "        scores.append(worst_score)\n",
    "    return [feature_names[i] for i in selected], scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "420e6f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 2 - Subtask 2: Backward Selection\n",
      "Step 1: compactness error - Score: 0.9723\n"
     ]
    }
   ],
   "source": [
    "model_lsvc = LinearSVC(random_state=42)\n",
    "backward_order, backward_scores = backward_selection(X_train_c, y_train_c, feature_names, model_lsvc)\n",
    "print(\"\\nTask 2 - Subtask 2: Backward Selection\")\n",
    "for i, (feature, score) in enumerate(zip(backward_order, backward_scores)):\n",
    "    print(f\"Step {i+1}: {feature} - Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f3e3b",
   "metadata": {},
   "source": [
    "## Subtask 3 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa889223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 2 - Subtask 3: Top 6 Features\n",
      "Forward Selection: ['mean concave points', 'worst texture', 'worst radius', 'worst concavity', 'texture error', 'mean concavity']\n",
      "Backward Selection: ['compactness error']\n",
      "Overlap: set()\n"
     ]
    }
   ],
   "source": [
    "forward_top6 = forward_order[:6]\n",
    "backward_top6 = backward_order[:6]\n",
    "\n",
    "print(\"\\nTask 2 - Subtask 3: Top 6 Features\")\n",
    "print(f\"Forward Selection: {forward_top6}\")\n",
    "print(f\"Backward Selection: {backward_top6}\")\n",
    "print(f\"Overlap: {set(forward_top6) & set(backward_top6)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
